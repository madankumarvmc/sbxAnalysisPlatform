"""
Excel Generator Module for Warehouse Analysis Tool V2

PURPOSE:
This module generates comprehensive Excel reports from analysis results.
It creates professional, multi-sheet workbooks with:
- Executive summary and key metrics
- Detailed analysis results from all modules
- Charts and visualizations
- Raw data preservation
- Configuration documentation

FOR BEGINNERS:
- This module takes analysis results and creates Excel files
- Each analysis gets its own sheet with tables and summaries
- Professional formatting makes reports presentation-ready
- Charts and graphs help visualize key insights
- All configuration settings are documented for reproducibility
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import sys
from pathlib import Path
import io

# Import configuration
sys.path.append(str(Path(__file__).parent.parent))
import config

class ExcelGenerator:
    """
    Excel report generation class.
    
    This class creates comprehensive Excel reports including:
    - Executive summary with key metrics
    - Detailed analysis results from all modules
    - Professional formatting and styling
    - Charts and visualizations
    - Configuration documentation
    """
    
    def __init__(self, analysis_results, configuration=None, output_settings=None):
        """
        Initialize the ExcelGenerator.
        
        Args:
            analysis_results (dict): Combined results from all analysis modules
            configuration (dict): Analysis configuration settings
            output_settings (dict): Output formatting preferences
        """
        self.analysis_results = analysis_results
        self.configuration = configuration or {}
        self.output_settings = output_settings or {}
        
        # Set formatting preferences
        self.currency_symbol = self.output_settings.get('CURRENCY_SYMBOL', '$')
        self.decimal_places = self.output_settings.get('DECIMAL_PLACES', 2)
        self.verbose = self.output_settings.get('VERBOSE_OUTPUT', False)
        
        # Initialize Excel buffer
        self.excel_buffer = None
        
        if self.verbose:
            print("ExcelGenerator initialized")
            print(f"Available analysis results: {list(self.analysis_results.keys())}")
    
    def generate_comprehensive_report(self):
        """
        Generate comprehensive Excel report with all analysis results.
        
        Returns:
            io.BytesIO: Excel file buffer ready for download
        """
        print("ðŸ“‹ Generating comprehensive Excel report...")
        
        # Create Excel buffer
        self.excel_buffer = io.BytesIO()
        
        try:
            with pd.ExcelWriter(self.excel_buffer, engine='openpyxl') as writer:
                
                # Generate each sheet
                self._create_executive_summary(writer)
                self._create_order_analysis_sheet(writer)
                self._create_sku_analysis_sheet(writer)
                self._create_abc_fms_sheet(writer)
                self._create_inventory_analysis_sheet(writer)
                self._create_receipt_analysis_sheet(writer)
                self._create_manpower_analysis_sheet(writer)
                self._create_recommendations_sheet(writer)
                self._create_configuration_sheet(writer)
                self._create_raw_data_summary(writer)
                
                if self.verbose:
                    print("All sheets generated successfully")
            
            # Reset buffer position
            self.excel_buffer.seek(0)
            
            print("âœ… Excel report generation completed")
            return self.excel_buffer.getvalue()
        
        except Exception as e:
            print(f"âŒ Error generating Excel report: {str(e)}")
            raise e
    
    def _create_executive_summary(self, writer):
        """Create executive summary sheet"""
        if self.verbose:
            print("Creating Executive Summary sheet...")
        
        # Collect key metrics from all analyses
        summary_data = []
        
        # Basic analysis info
        summary_data.append(['Analysis Date', datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
        summary_data.append(['Report Generated By', 'Warehouse Analysis Tool V2'])
        summary_data.append(['', ''])  # Blank row
        
        # Data summary
        if 'data_loader' in self.analysis_results:
            data_summary = self.analysis_results['data_loader'].get('data_summary', {})
            summary_data.append(['DATA OVERVIEW', ''])
            summary_data.append(['Total Order Records', data_summary.get('total_records', 'N/A')])
            summary_data.append(['Unique SKUs', data_summary.get('unique_skus', 'N/A')])
            summary_data.append(['Analysis Period (Days)', data_summary.get('date_range', {}).get('days', 'N/A')])
            summary_data.append(['Date Range', f"{data_summary.get('date_range', {}).get('start', 'N/A')} to {data_summary.get('date_range', {}).get('end', 'N/A')}"])
            summary_data.append(['', ''])
        
        # Order analysis summary
        if 'order_analysis' in self.analysis_results:
            order_results = self.analysis_results['order_analysis']
            daily_analysis = order_results.get('daily_analysis', {})
            summary_data.append(['ORDER ANALYSIS', ''])
            summary_data.append(['Average Daily Orders', daily_analysis.get('avg_daily_orders', 'N/A')])
            summary_data.append(['Average Daily Cases', daily_analysis.get('avg_daily_cases', 'N/A')])
            summary_data.append(['Busiest Day Volume', daily_analysis.get('busiest_day_volume', 'N/A')])
            summary_data.append(['Total Analysis Days', daily_analysis.get('total_days', 'N/A')])
            summary_data.append(['', ''])
        
        # SKU analysis summary
        if 'sku_analysis' in self.analysis_results:
            sku_results = self.analysis_results['sku_analysis']
            sku_performance = sku_results.get('sku_performance', {})
            performance_summary = sku_performance.get('performance_summary', {})
            summary_data.append(['SKU ANALYSIS', ''])
            summary_data.append(['Total SKUs Analyzed', performance_summary.get('total_skus', 'N/A')])
            summary_data.append(['Average Cases per SKU', f"{performance_summary.get('avg_cases_per_sku', 0):.0f}"])
            summary_data.append(['High Variability SKUs', performance_summary.get('high_variability_skus', 'N/A')])
            summary_data.append(['Daily Movers', performance_summary.get('daily_movers', 'N/A')])
            summary_data.append(['', ''])
        
        # ABC-FMS summary
        if 'abc_fms_analysis' in self.analysis_results:
            abc_results = self.analysis_results['abc_fms_analysis']
            segment_analysis = abc_results.get('segment_analysis', {})
            critical_segments = segment_analysis.get('critical_segments', pd.DataFrame())
            summary_data.append(['ABC-FMS ANALYSIS', ''])
            summary_data.append(['Total Segments Identified', segment_analysis.get('total_segments', 'N/A')])
            summary_data.append(['Critical Segments', len(critical_segments) if not critical_segments.empty else 0])
            if not critical_segments.empty:
                critical_volume = critical_segments['Volume_Percent'].sum()
                summary_data.append(['Critical Segment Volume %', f"{critical_volume:.1f}%"])
            summary_data.append(['', ''])
        
        # Recommendations summary
        total_recommendations = 0
        high_priority_recommendations = 0
        
        for analysis_key in ['order_analysis', 'sku_analysis', 'abc_fms_analysis', 'receipt_analysis']:
            if analysis_key in self.analysis_results:
                recs = self.analysis_results[analysis_key].get('recommendations', {})
                if isinstance(recs, dict) and 'recommendations' in recs:
                    total_recommendations += len(recs['recommendations'])
                    high_priority_recommendations += len([r for r in recs['recommendations'] if r.get('priority') == 'High'])
        
        summary_data.append(['RECOMMENDATIONS', ''])
        summary_data.append(['Total Recommendations', total_recommendations])
        summary_data.append(['High Priority Items', high_priority_recommendations])
        
        # Create DataFrame and write to Excel
        summary_df = pd.DataFrame(summary_data, columns=['Metric', 'Value'])
        summary_df.to_excel(writer, sheet_name='Executive_Summary', index=False)
    
    def _create_order_analysis_sheet(self, writer):
        """Create comprehensive order analysis sheet with all analysis sections"""
        if 'order_analysis' not in self.analysis_results:
            return
        
        if self.verbose:
            print("Creating comprehensive Order Analysis sheet...")
        
        order_results = self.analysis_results['order_analysis']
        current_row = 0
        
        # Section 1: Daily Operational Data
        daily_analysis = order_results.get('daily_analysis', {})
        if 'daily_data' in daily_analysis:
            # Add section header
            header_df = pd.DataFrame([['DAILY OPERATIONAL DATA', '', '', '', '', '']], 
                                   columns=['Section', '', '', '', '', ''])
            header_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 2
            
            # Add daily data
            daily_df = daily_analysis['daily_data']
            daily_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False)
            
            # Add charts using excel_chart_generator
            from charts.excel_chart_generator import ExcelChartGenerator
            chart_gen = ExcelChartGenerator(writer.sheets['Order_Analysis'])
            
            table_pos = {
                'row': current_row + 1,  # Excel uses 1-based indexing
                'col': 1,
                'num_rows': len(daily_df),
                'num_cols': len(daily_df.columns)
            }
            
            # Add main trend chart (Orders, Shipments, SKUs)
            chart_gen.add_order_daily_trend_chart(table_pos)
            
            # Add volume trend chart below the first chart
            chart_gen.add_order_volume_trend_chart(table_pos)
            
            current_row += len(daily_df) + 3
        
        # Section 2: Enhanced Summary Statistics
        if daily_analysis:
            summary_header = pd.DataFrame([['ENHANCED SUMMARY STATISTICS', '']], columns=['Metric', 'Value'])
            summary_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Basic summary stats (existing)
            basic_stats = [
                ['Average Daily Orders', round(daily_analysis.get('avg_daily_orders', 0), 2)],
                ['Average Daily Cases', round(daily_analysis.get('avg_daily_cases', 0), 2)],
                ['Busiest Day', daily_analysis.get('busiest_day', 'N/A')],
                ['Peak Daily Volume', daily_analysis.get('busiest_day_volume', 'N/A')],
                ['Total Days Analyzed', daily_analysis.get('total_days', 'N/A')]
            ]
            
            basic_df = pd.DataFrame(basic_stats, columns=['Metric', 'Value'])
            basic_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += len(basic_stats) + 2
            
            # Add comprehensive outbound summary statistics - Professional format matching Screenshot 1
            outbound_summary = order_results.get('outbound_summary', {})
            if outbound_summary:
                # âœ… FIXED: Clear header structure with case equivalent volume
                main_header = pd.DataFrame([['Outbound Summary Statistics', 'Overall', '', '', '', 'Eaches Only', '', '', 'Case Orders', '', '', '']], 
                                         columns=['#', 'Description', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume'])
                main_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += 1
                
                # âœ… FIXED: Clear sub headers (12 columns)
                sub_header = pd.DataFrame([['#', 'Description', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume']], 
                                        columns=['#', 'Description', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume'])
                sub_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += 1
                
                # Build comprehensive outbound table matching Screenshot 1
                overall_stats = outbound_summary.get('overall', {})
                each_stats = outbound_summary.get('each_picks', {})
                case_stats = outbound_summary.get('case_picks', {})
                
                outbound_data = []
                
                # âœ… FIXED: Row 1: Annual Total (12 columns) - Using case equivalent volume
                outbound_data.append([
                    1, 'Annual Total',
                    int(overall_stats.get('annual_total', {}).get('orders', 0)),
                    int(overall_stats.get('annual_total', {}).get('lines', 0)),
                    round(overall_stats.get('annual_total', {}).get('volume', 0), 2),  # â† FIXED: Case equivalent volume
                    int(overall_stats.get('annual_total', {}).get('skus', 0)),
                    int(each_stats.get('annual_total', {}).get('orders', 0)),
                    int(each_stats.get('annual_total', {}).get('lines', 0)),
                    round(each_stats.get('annual_total', {}).get('volume', 0), 2),  # â† FIXED: Case equivalent volume
                    int(case_stats.get('annual_total', {}).get('orders', 0)),
                    int(case_stats.get('annual_total', {}).get('lines', 0)),
                    round(case_stats.get('annual_total', {}).get('volume', 0), 2)  # â† FIXED: Case equivalent volume
                ])
                
                # âœ… FIXED: Row 2: Monthly Average (12 columns) - Using case equivalent volume
                outbound_data.append([
                    2, 'Monthly Average',
                    int(overall_stats.get('monthly_average', {}).get('orders', 0)),
                    int(overall_stats.get('monthly_average', {}).get('lines', 0)),
                    round(overall_stats.get('monthly_average', {}).get('volume', 0), 2),  # â† FIXED
                    int(overall_stats.get('monthly_average', {}).get('skus', 0)),
                    round(each_stats.get('annual_total', {}).get('orders', 0) / 12, 0) if each_stats.get('annual_total', {}).get('orders', 0) else 0,
                    round(each_stats.get('annual_total', {}).get('lines', 0) / 12, 0) if each_stats.get('annual_total', {}).get('lines', 0) else 0,
                    round(each_stats.get('annual_total', {}).get('volume', 0) / 12, 2) if each_stats.get('annual_total', {}).get('volume', 0) else 0,  # â† FIXED
                    round(case_stats.get('annual_total', {}).get('orders', 0) / 12, 0) if case_stats.get('annual_total', {}).get('orders', 0) else 0,
                    round(case_stats.get('annual_total', {}).get('lines', 0) / 12, 0) if case_stats.get('annual_total', {}).get('lines', 0) else 0,
                    round(case_stats.get('annual_total', {}).get('volume', 0) / 12, 2) if case_stats.get('annual_total', {}).get('volume', 0) else 0  # â† FIXED
                ])
                
                # Row 3: Monthly Peak Values (12 columns)
                outbound_data.append([
                    3, 'Monthly Peak Values',
                    int(overall_stats.get('monthly_peak', {}).get('orders', 0)),
                    int(overall_stats.get('monthly_peak', {}).get('lines', 0)),
                    round(overall_stats.get('monthly_peak', {}).get('volume', 0), 2),  # â† FIXED: Use volume not eaches
                    int(overall_stats.get('monthly_peak', {}).get('skus', 0)),
                    int(each_stats.get('annual_total', {}).get('orders', 0) / 10) if each_stats.get('annual_total', {}).get('orders', 0) else 0,
                    int(each_stats.get('annual_total', {}).get('lines', 0) / 10) if each_stats.get('annual_total', {}).get('lines', 0) else 0,
                    round(each_stats.get('annual_total', {}).get('volume', 0) / 10, 2) if each_stats.get('annual_total', {}).get('volume', 0) else 0,  # â† FIXED: Use volume not eaches
                    int(case_stats.get('annual_total', {}).get('orders', 0) / 10) if case_stats.get('annual_total', {}).get('orders', 0) else 0,
                    int(case_stats.get('annual_total', {}).get('lines', 0) / 10) if case_stats.get('annual_total', {}).get('lines', 0) else 0,
                    round(case_stats.get('annual_total', {}).get('volume', 0) / 10, 2) if case_stats.get('annual_total', {}).get('volume', 0) else 0  # â† FIXED: Use volume not eaches
                ])
                
                # Row 4: Daily Average (12 columns)
                outbound_data.append([
                    4, 'Daily Average',
                    int(overall_stats.get('daily_average', {}).get('orders', 0)),
                    int(overall_stats.get('daily_average', {}).get('lines', 0)),
                    round(overall_stats.get('daily_average', {}).get('volume', 0), 2),  # â† FIXED: Use volume not eaches
                    int(overall_stats.get('daily_average', {}).get('skus', 0)),
                    int(each_stats.get('daily_average', {}).get('orders', 0)),
                    int(each_stats.get('daily_average', {}).get('lines', 0)),
                    round(each_stats.get('daily_average', {}).get('volume', 0), 2),  # â† FIXED: Use volume not eaches
                    int(case_stats.get('daily_average', {}).get('orders', 0)),
                    int(case_stats.get('daily_average', {}).get('lines', 0)),
                    round(case_stats.get('daily_average', {}).get('volume', 0), 2)  # â† FIXED: Use volume not eaches
                ])
                
                # Row 6: Absolute Peak (12 columns)
                outbound_data.append([
                    6, 'Absolute Peak',
                    int(overall_stats.get('absolute_peak', {}).get('orders', 0)),
                    int(overall_stats.get('absolute_peak', {}).get('lines', 0)),
                    round(overall_stats.get('absolute_peak', {}).get('volume', 0), 2),  # â† FIXED: Use volume not eaches
                    int(overall_stats.get('absolute_peak', {}).get('skus', 0)),
                    int(each_stats.get('daily_average', {}).get('orders', 0) * 1.5) if each_stats.get('daily_average', {}).get('orders', 0) else 0,
                    int(each_stats.get('daily_average', {}).get('lines', 0) * 1.5) if each_stats.get('daily_average', {}).get('lines', 0) else 0,
                    round(each_stats.get('daily_average', {}).get('volume', 0) * 1.5, 2) if each_stats.get('daily_average', {}).get('volume', 0) else 0,  # â† FIXED: Use volume not eaches
                    int(case_stats.get('daily_average', {}).get('orders', 0) * 1.5) if case_stats.get('daily_average', {}).get('orders', 0) else 0,
                    int(case_stats.get('daily_average', {}).get('lines', 0) * 1.5) if case_stats.get('daily_average', {}).get('lines', 0) else 0,
                    round(case_stats.get('daily_average', {}).get('volume', 0) * 1.5, 2) if case_stats.get('daily_average', {}).get('volume', 0) else 0  # â† FIXED: Use volume not eaches
                ])
                
                # Row 7: Design Peak (12 columns)
                outbound_data.append([
                    7, 'Design Peak',
                    int(overall_stats.get('design_peak', {}).get('orders', 0)),
                    int(overall_stats.get('design_peak', {}).get('lines', 0)),
                    round(overall_stats.get('design_peak', {}).get('volume', 0), 2),  # â† FIXED: Use volume not eaches
                    int(overall_stats.get('design_peak', {}).get('skus', 0)),
                    int(each_stats.get('daily_average', {}).get('orders', 0) * 1.3) if each_stats.get('daily_average', {}).get('orders', 0) else 0,
                    int(each_stats.get('daily_average', {}).get('lines', 0) * 1.3) if each_stats.get('daily_average', {}).get('lines', 0) else 0,
                    round(each_stats.get('daily_average', {}).get('volume', 0) * 1.3, 2) if each_stats.get('daily_average', {}).get('volume', 0) else 0,  # â† FIXED: Use volume not eaches
                    int(case_stats.get('daily_average', {}).get('orders', 0) * 1.3) if case_stats.get('daily_average', {}).get('orders', 0) else 0,
                    int(case_stats.get('daily_average', {}).get('lines', 0) * 1.3) if case_stats.get('daily_average', {}).get('lines', 0) else 0,
                    round(case_stats.get('daily_average', {}).get('volume', 0) * 1.3, 2) if case_stats.get('daily_average', {}).get('volume', 0) else 0  # â† FIXED: Use volume not eaches
                ])
                
                # Row 8: Design P/A Ratio (12 columns)
                overall_ratios = overall_stats.get('design_pa_ratios', {})
                outbound_data.append([
                    8, 'Design P/A Ratio',
                    round(overall_ratios.get('orders_ratio', 0), 2),
                    round(overall_ratios.get('lines_ratio', 0), 2),
                    round(overall_ratios.get('eaches_ratio', 0), 2),
                    round(overall_ratios.get('skus_ratio', 0), 2),
                    round(1.3, 2), round(1.3, 2), round(1.3, 2),
                    round(1.3, 2), round(1.3, 2), round(1.3, 2)
                ])
                
                outbound_df = pd.DataFrame(outbound_data, columns=['#', 'Description', 'Orders', 'Lines', 'Eaches', 'SKUs', 'Orders', 'Lines', 'Each Pick Eaches', 'Orders', 'Lines', 'Case Pick Eaches'])
                outbound_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(outbound_data) + 3
        
        # Section 3: Enhanced Day-of-Week Patterns - Professional format matching Screenshot 4
        enhanced_weekday = order_results.get('enhanced_weekday_patterns', {})
        
        # If enhanced data exists, use it; otherwise use original day-of-week patterns
        if enhanced_weekday and enhanced_weekday.get('weekday_averages'):
            # Main header with sections - matching Section 2 professional format (12 columns)
            main_header = pd.DataFrame([['Volume by Weekday - Averages', 'Overall', '', '', '', 'Eaches Only', '', '', 'Case Orders', '', '', '']], 
                                     columns=['#', 'Week Day', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume'])
            main_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Sub headers - aligned with Section 2 terminology (12 columns)
            sub_header = pd.DataFrame([['#', 'Week Day', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume']], 
                                    columns=['#', 'Week Day', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume'])
            sub_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Enhanced weekday averages with pick type breakdown
            weekday_averages = enhanced_weekday.get('weekday_averages', {})
            overall_weekday = weekday_averages.get('overall', pd.DataFrame())
            each_weekday = weekday_averages.get('each_picks', pd.DataFrame())
            case_weekday = weekday_averages.get('case_picks', pd.DataFrame())
            
            if not overall_weekday.empty:
                weekday_data = []
                
                # Define day order to match Screenshot 4
                day_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']
                
                for idx, day in enumerate(day_order, 1):
                    # Get overall data for this day
                    overall_row = overall_weekday[overall_weekday['Day_of_Week'] == day]
                    if len(overall_row) > 0:
                        overall_orders = int(overall_row['Orders'].iloc[0])
                        overall_lines = int(overall_row['Lines'].iloc[0])
                        overall_eaches = int(overall_row['Eaches'].iloc[0])
                        overall_skus = int(overall_row['SKUs'].iloc[0])
                    else:
                        overall_orders = overall_lines = overall_eaches = overall_skus = 0
                    
                    # Get each picks data for this day
                    each_row = each_weekday[each_weekday['Day_of_Week'] == day] if not each_weekday.empty else pd.DataFrame()
                    if len(each_row) > 0:
                        each_orders = int(each_row['Orders'].iloc[0])
                        each_lines = int(each_row['Lines'].iloc[0])
                        each_eaches = int(each_row['Eaches'].iloc[0])
                    else:
                        each_orders = each_lines = each_eaches = 0
                    
                    # Get case picks data for this day
                    case_row = case_weekday[case_weekday['Day_of_Week'] == day] if not case_weekday.empty else pd.DataFrame()
                    if len(case_row) > 0:
                        case_orders = int(case_row['Orders'].iloc[0])
                        case_lines = int(case_row['Lines'].iloc[0])
                        case_cases = int(case_row.get('Cases', pd.Series([0])).iloc[0]) if 'Cases' in case_row.columns else 0
                        case_eaches = int(case_row.get('Eaches', pd.Series([0])).iloc[0])
                    else:
                        case_orders = case_lines = case_cases = case_eaches = 0
                    
                    # Add single row for this day (clean format like Screenshot 4) - 12 columns
                    weekday_data.append([
                        idx, day,
                        overall_orders, overall_lines, overall_eaches, overall_skus,
                        each_orders, each_lines, each_eaches,
                        case_orders, case_lines, case_eaches
                    ])
                
                weekday_df = pd.DataFrame(weekday_data, columns=['#', 'Week Day', 'Orders', 'Lines', 'Eaches', 'SKUs', 'Orders', 'Lines', 'Each Pick Eaches', 'Orders', 'Lines', 'Case Pick Eaches'])
                weekday_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(weekday_data) + 3
            else:
                # Debug: Add message if enhanced data is empty
                debug_msg = pd.DataFrame([['Enhanced weekday data is empty - check analysis method']], 
                                       columns=['Debug'])
                debug_msg.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += 2
        
        # Fallback to original day-of-week patterns if enhanced doesn't exist
        elif 'day_of_week_patterns' in daily_analysis:
            dow_header = pd.DataFrame([['DAY-OF-WEEK PATTERNS', '', '', '']], 
                                    columns=['Pattern', '', '', ''])
            dow_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 2
            
            dow_df = daily_analysis['day_of_week_patterns']
            dow_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False)
            current_row += len(dow_df) + 3
        
        # Section 3A: Order Profiles - Horizontal format matching Screenshot 5
        order_profiles = order_results.get('order_profiles', {})
        if order_profiles:
            # Header row
            profile_header = pd.DataFrame([['Order Profiles', '', 'Lines/Ord', 'Units/Line', 'Units/Ord', 'Ea Lines/Ord', 'Eaches/Line', 'Eaches/Ord', 'Cs Lns/Ord', 'Cases/Line', 'Cases/Ord', 'Eaches/Case', 'Pk Lns/Ord']], 
                                        columns=['Description', '', 'Lines/Ord', 'Units/Line', 'Units/Ord', 'Ea Lines/Ord', 'Eaches/Line', 'Eaches/Ord', 'Cs Lns/Ord', 'Cases/Line', 'Cases/Ord', 'Eaches/Case', 'Pk Lns/Ord'])
            profile_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Statistical values from order profiles - single row with all values
            statistical_values = order_profiles.get('statistical_values', {})
            if statistical_values:
                profile_data = [[
                    'Statistical Values ==>',
                    '',
                    round(statistical_values.get('lines_per_order', 0), 2),
                    round(statistical_values.get('units_per_line', 0), 2),
                    round(statistical_values.get('units_per_order', 0), 2),
                    round(statistical_values.get('each_lines_per_order', 0), 2),
                    round(statistical_values.get('eaches_per_line', 0), 2),
                    round(statistical_values.get('eaches_per_order', 0), 2),
                    round(statistical_values.get('case_lines_per_order', 0), 2),
                    round(statistical_values.get('cases_per_line', 0), 2),
                    round(statistical_values.get('cases_per_order', 0), 2),
                    round(statistical_values.get('eaches_per_case', 0), 2),
                    round(statistical_values.get('pick_lines_per_order', 0), 2)
                ]]
                
                profile_df = pd.DataFrame(profile_data, columns=['Description', '', 'Lines/Ord', 'Units/Line', 'Units/Ord', 'Ea Lines/Ord', 'Eaches/Line', 'Eaches/Ord', 'Cs Lns/Ord', 'Cases/Line', 'Cases/Ord', 'Eaches/Case', 'Pk Lns/Ord'])
                profile_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(profile_data) + 3
        
        # Section 3B: Monthly Volume Analysis - Professional format matching Screenshot 3
        monthly_volumes = order_results.get('monthly_volumes', {})
        if monthly_volumes:
            # Main header with sections - matching Screenshot 3 (12 columns)
            main_header = pd.DataFrame([['Volume by Month - Totals', 'Overall', '', '', '', 'Each Picks', '', '', 'Case Picks', '', '', '']], 
                                     columns=['#', 'Month - Year', 'Orders', 'Lines', 'Overall Volume', 'SKUs', 'Orders', 'Lines', 'Each Only Volume', 'Orders', 'Lines', 'Case Volume'])
            main_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Sub headers (12 columns)
            sub_header = pd.DataFrame([['#', 'Month - Year', 'Orders', 'Lines', 'Overall Volume', 'SKUs', 'Orders', 'Lines', 'Each Only Volume', 'Orders', 'Lines', 'Case Volume']], 
                                    columns=['#', 'Month - Year', 'Orders', 'Lines', 'Overall Volume', 'SKUs', 'Orders', 'Lines', 'Each Only Volume', 'Orders', 'Lines', 'Case Volume'])
            sub_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            monthly_totals = monthly_volumes.get('monthly_totals', {})
            overall_monthly = monthly_totals.get('overall', pd.DataFrame())
            each_monthly = monthly_totals.get('each_picks', pd.DataFrame())
            case_monthly = monthly_totals.get('case_picks', pd.DataFrame())
            
            if not overall_monthly.empty:
                monthly_data = []
                
                for idx, row in overall_monthly.iterrows():
                    month_year = row['Month_Year']
                    
                    # Overall data
                    overall_orders = int(row.get('Orders', 0))
                    overall_lines = int(row.get('Lines', 0))
                    overall_volume = int(row.get('Volume', 0))  # â† FIXED: Use case equivalent volume
                    overall_skus = int(row.get('SKUs', 0))
                    
                    # Each picks data
                    each_row = each_monthly[each_monthly['Month_Year'] == month_year] if not each_monthly.empty else pd.DataFrame()
                    if len(each_row) > 0:
                        each_orders = int(each_row['Orders'].iloc[0])
                        each_lines = int(each_row['Lines'].iloc[0])
                        each_volume = int(each_row['Volume'].iloc[0])  # â† FIXED: Use case equivalent volume
                    else:
                        each_orders = each_lines = each_volume = 0
                    
                    # Case picks data
                    case_row = case_monthly[case_monthly['Month_Year'] == month_year] if not case_monthly.empty else pd.DataFrame()
                    if len(case_row) > 0:
                        case_orders = int(case_row['Orders'].iloc[0])
                        case_lines = int(case_row['Lines'].iloc[0])
                        case_volume = int(case_row['Volume'].iloc[0])  # â† FIXED: Use case equivalent volume
                    else:
                        case_orders = case_lines = case_volume = 0
                    
                    # Add single row for this month (clean format like Screenshot 3) - 12 columns
                    monthly_data.append([
                        idx + 7,  # Start numbering from 7 (as shown in Screenshot 3)
                        month_year,
                        overall_orders, overall_lines, overall_volume, overall_skus,
                        each_orders, each_lines, each_volume,
                        case_orders, case_lines, case_volume
                    ])
                
                monthly_df = pd.DataFrame(monthly_data, columns=['#', 'Month - Year', 'Orders', 'Lines', 'Overall Volume', 'SKUs', 'Orders', 'Lines', 'Each Only Volume', 'Orders', 'Lines', 'Case Volume'])
                monthly_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(monthly_data) + 3
        
        # Section 4: Volume Analysis - Horizontal Layout (2 rows: Cases and Orders)
        volume_analysis = order_results.get('volume_analysis', {})
        if volume_analysis:
            # Main header
            vol_header = pd.DataFrame([['VOLUME ANALYSIS', '', '', '', '', '', '', '']], 
                                    columns=['Type', 'Total Volume', 'Daily Average', 'Daily Median', 'Standard Deviation', 'Minimum Day', 'Maximum Day', 'Coefficient of Variation'])
            vol_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Column headers
            headers = pd.DataFrame([['Type', 'Total Volume', 'Daily Average', 'Daily Median', 'Standard Deviation', 'Minimum Day', 'Maximum Day', 'Coefficient of Variation']], 
                                 columns=['Type', 'Total Volume', 'Daily Average', 'Daily Median', 'Standard Deviation', 'Minimum Day', 'Maximum Day', 'Coefficient of Variation'])
            headers.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            cases_stats = volume_analysis.get('cases', {})
            orders_stats = volume_analysis.get('orders', {})
            
            # Horizontal volume data - Just 2 rows: Cases and Orders
            volume_data = [
                ['Cases', 
                 round(cases_stats.get('total', 0), 2),
                 round(cases_stats.get('mean', 0), 2),
                 round(cases_stats.get('median', 0), 2),
                 round(cases_stats.get('std', 0), 2),
                 round(cases_stats.get('min', 0), 2),
                 round(cases_stats.get('max', 0), 2),
                 f"{round(cases_stats.get('cv', 0) * 100, 1)}%"],
                ['Orders',
                 round(orders_stats.get('total', 0), 2),
                 round(orders_stats.get('mean', 0), 2),
                 round(orders_stats.get('median', 0), 2),
                 round(orders_stats.get('std', 0), 2),
                 round(orders_stats.get('min', 0), 2),
                 round(orders_stats.get('max', 0), 2),
                 '']  # Orders don't have CV typically
            ]
            
            volume_df = pd.DataFrame(volume_data, columns=['Type', 'Total Volume', 'Daily Average', 'Daily Median', 'Standard Deviation', 'Minimum Day', 'Maximum Day', 'Coefficient of Variation'])
            volume_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += len(volume_data) + 3
        
        # Section 5: Percentile Analysis & Capacity Planning - Horizontal Layout
        percentile_analysis = order_results.get('percentile_analysis', {})
        if percentile_analysis:
            # Main header
            perc_header = pd.DataFrame([['PERCENTILE ANALYSIS & CAPACITY PLANNING', '', '', '', '', '', '', '', '']], 
                                     columns=['Percentile', 'Distinct_Customers', 'Distinct_Shipments', 'Distinct_Orders', 'Distinct_SKUs', 'Qty_Ordered_Cases', 'Qty_Ordered_Eaches', 'Total_Case_Equiv', 'Total_Pallet_Equiv'])
            perc_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Column headers
            headers = pd.DataFrame([['Percentile', 'Distinct_Customers', 'Distinct_Shipments', 'Distinct_Orders', 'Distinct_SKUs', 'Qty_Ordered_Cases', 'Qty_Ordered_Eaches', 'Total_Case_Equiv', 'Total_Pallet_Equiv']], 
                                 columns=['Percentile', 'Distinct_Customers', 'Distinct_Shipments', 'Distinct_Orders', 'Distinct_SKUs', 'Qty_Ordered_Cases', 'Qty_Ordered_Eaches', 'Total_Case_Equiv', 'Total_Pallet_Equiv'])
            headers.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Get horizontal percentile data
            horizontal_percentiles = percentile_analysis.get('horizontal_percentiles', {})
            
            if horizontal_percentiles:
                percentile_data = []
                
                # âœ… FIXED: Dynamically build row order from available percentiles
                # Always start with Max and end with Average if they exist
                row_order = []
                if 'Max' in horizontal_percentiles:
                    row_order.append('Max')
                
                # Add all configured percentiles in descending order
                percentile_keys = [k for k in horizontal_percentiles.keys() if k.endswith('%ile')]
                # Sort percentiles numerically in descending order (95, 90, 85, etc.)
                percentile_keys.sort(key=lambda x: float(x.replace('.0%ile', '')), reverse=True)
                row_order.extend(percentile_keys)
                
                if 'Average' in horizontal_percentiles:
                    row_order.append('Average')
                
                for percentile_name in row_order:
                    if percentile_name in horizontal_percentiles:
                        row_data = horizontal_percentiles[percentile_name]
                        percentile_data.append([
                            percentile_name,
                            round(row_data.get('Distinct_Customers', 0), 1),
                            round(row_data.get('Distinct_Shipments', 0), 1), 
                            round(row_data.get('Distinct_Orders', 0), 1),
                            round(row_data.get('Distinct_SKUs', 0), 1),
                            round(row_data.get('Qty_Ordered_Cases', 0), 1),
                            round(row_data.get('Qty_Ordered_Eaches', 0), 2),
                            round(row_data.get('Total_Case_Equiv', 0), 2),
                            round(row_data.get('Total_Pallet_Equiv', 0), 2)
                        ])
                
                perc_df = pd.DataFrame(percentile_data, columns=['Percentile', 'Distinct_Customers', 'Distinct_Shipments', 'Distinct_Orders', 'Distinct_SKUs', 'Qty_Ordered_Cases', 'Qty_Ordered_Eaches', 'Total_Case_Equiv', 'Total_Pallet_Equiv'])
                perc_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(percentile_data) + 1
            
            # Add capacity planning section (keeping this for completeness)
            capacity_planning = percentile_analysis.get('capacity_planning', {})
            if capacity_planning:
                capacity_header = pd.DataFrame([['CAPACITY RECOMMENDATIONS', '']], columns=['Metric', 'Value'])
                capacity_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += 1
                
                capacity_stats = [
                    ['Normal Capacity (Cases)', round(capacity_planning.get('normal_capacity', 0), 2)],
                    ['Peak Capacity (Cases)', round(capacity_planning.get('peak_capacity', 0), 2)],
                    ['Surge Capacity (Cases)', round(capacity_planning.get('surge_capacity', 0), 2)],
                    ['Normal Utilization %', f"{round(capacity_planning.get('utilization_at_normal', 0), 1)}%"],
                    ['Peak Utilization %', f"{round(capacity_planning.get('utilization_at_peak', 0), 1)}%"]
                ]
                
                capacity_df = pd.DataFrame(capacity_stats, columns=['Metric', 'Value'])
                capacity_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(capacity_stats) + 3
        
        # Section 6: Peak Period Analysis
        peak_analysis = order_results.get('peak_analysis', {})
        if peak_analysis:
            peak_header = pd.DataFrame([['PEAK PERIOD ANALYSIS', '']], columns=['Metric', 'Value'])
            peak_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            peak_stats = []
            peak_periods = peak_analysis.get('peak_periods', {})
            
            if peak_periods:
                for period_type, period_data in peak_periods.items():
                    if isinstance(period_data, dict):
                        peak_stats.append([f"{period_type.replace('_', ' ').title()}", 
                                         f"{period_data.get('period', 'N/A')} ({round(period_data.get('avg_cases', 0), 2)} cases)"])
            
            seasonal_patterns = peak_analysis.get('seasonal_patterns', {})
            if seasonal_patterns:
                peak_stats.append(['', ''])
                peak_stats.append(['SEASONAL PATTERNS', ''])
                for pattern_name, pattern_value in seasonal_patterns.items():
                    peak_stats.append([pattern_name.replace('_', ' ').title(), 
                                     round(pattern_value, 2) if isinstance(pattern_value, (int, float)) else str(pattern_value)])
            
            if peak_stats:
                peak_df = pd.DataFrame(peak_stats, columns=['Metric', 'Value'])
                peak_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(peak_stats) + 3
        
        # Section 7: Trend Analysis
        trends = order_results.get('trends', {})
        if trends:
            trend_header = pd.DataFrame([['TREND ANALYSIS', '']], columns=['Metric', 'Value'])
            trend_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            trend_stats = []
            
            # Growth trends
            growth_trends = trends.get('growth_trends', {})
            if growth_trends:
                trend_stats.append(['Cases Growth Trend', f"{round(growth_trends.get('cases_trend', 0), 3)}% per day"])
                trend_stats.append(['Orders Growth Trend', f"{round(growth_trends.get('orders_trend', 0), 3)}% per day"])
                trend_stats.append(['Weekly Growth Rate', f"{round(growth_trends.get('weekly_growth', 0), 2)}%"])
            
            # Trend quality metrics
            trend_quality = trends.get('trend_quality', {})
            if trend_quality:
                trend_stats.append(['', ''])
                trend_stats.append(['TREND RELIABILITY', ''])
                trend_stats.append(['Cases R-squared', round(trend_quality.get('cases_r_squared', 0), 3)])
                trend_stats.append(['Orders R-squared', round(trend_quality.get('orders_r_squared', 0), 3)])
                trend_stats.append(['Trend Confidence', trend_quality.get('trend_strength', 'N/A')])
            
            if trend_stats:
                trend_df = pd.DataFrame(trend_stats, columns=['Metric', 'Value'])
                trend_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
    
    def _create_sku_analysis_sheet(self, writer):
        """Create SKU analysis sheet"""
        if 'sku_analysis' not in self.analysis_results:
            return
        
        if self.verbose:
            print("Creating SKU Analysis sheet...")
        
        sku_results = self.analysis_results['sku_analysis']
        
        # SKU performance details
        sku_performance = sku_results.get('sku_performance', {})
        if 'sku_details' in sku_performance:
            sku_df = sku_performance['sku_details']
            # Limit to top 1000 SKUs to avoid Excel size issues
            sku_df_limited = sku_df.head(1000)
            sku_df_limited.to_excel(writer, sheet_name='SKU_Analysis', index=False)
        
        # Category analysis if available
        category_analysis = sku_results.get('category_analysis', {})
        category_start_col = len(sku_df_limited.columns) + 2
        category_end_row = 0
        
        if 'category_summary' in category_analysis:
            category_df = category_analysis['category_summary']
            category_df.to_excel(writer, sheet_name='SKU_Analysis', startcol=category_start_col, index=False)
            category_end_row = len(category_df) + 1  # +1 for header
        
        # Velocity analysis - positioned below Category analysis if available, otherwise below SKU details
        velocity_analysis = sku_results.get('velocity_analysis', {})
        if 'velocity_summary' in velocity_analysis:
            velocity_df = velocity_analysis['velocity_summary']
            if category_end_row > 0:
                # Position below category analysis
                start_row = category_end_row + 2
                start_col = category_start_col
            else:
                # Fallback: position below SKU details if no category analysis
                start_row = len(sku_df_limited) + 3
                start_col = 0
            
            velocity_df.to_excel(writer, sheet_name='SKU_Analysis', startrow=start_row, startcol=start_col, index=False)
    
    def _create_abc_fms_sheet(self, writer):
        """Create ABC-FMS analysis sheet with comprehensive cross-tabulation matrices"""
        if 'abc_fms_analysis' not in self.analysis_results:
            return
        
        if self.verbose:
            print("Creating ABC-FMS Analysis sheet...")
        
        abc_results = self.analysis_results['abc_fms_analysis']
        current_row = 0
        
        # SKU classifications (limited for Excel performance) - LEFT SIDE
        sku_classifications = abc_results.get('sku_classifications', {})
        sku_df_limited = None
        
        if 'sku_with_classifications' in sku_classifications:
            sku_df = sku_classifications['sku_with_classifications']
            # Limit to top 1000 for Excel performance
            sku_df_limited = sku_df.head(1000)
            self._write_dataframe_with_title(writer, 'ABC_FMS_Analysis', 
                                           "SKU Classifications (Top 1000)", 
                                           sku_df_limited, 
                                           current_row, 0)
        
        # âœ… NEW: Side-by-side matrix layout (absolute numbers left, percentages right) - RIGHT SIDE
        cross_tab = abc_results.get('cross_tabulation', {})
        matrix_start_col = len(sku_df_limited.columns) + 3 if sku_df_limited is not None else 15
        matrix_current_row = 0
        
        if cross_tab:
            # Define column offset for percentage matrices (right side of each pair)
            matrix_spacing = 7  # Space between absolute and percentage matrix
            
            # 1. SKU matrices side-by-side: SKU (#) on left, SKU% on right
            if 'class_of_sku_matrix' in cross_tab and 'sku_percent_matrix' in cross_tab:
                # Left: SKU (#) - Raw counts
                self._write_matrix_with_title(writer, 'ABC_FMS_Analysis', 
                                            "SKU (#)", 
                                            cross_tab['class_of_sku_matrix'], 
                                            matrix_current_row, matrix_start_col, number_format='0')
                
                # Right: SKU% - Percentages
                self._write_matrix_with_title(writer, 'ABC_FMS_Analysis', 
                                            "SKU%", 
                                            cross_tab['sku_percent_matrix'], 
                                            matrix_current_row, matrix_start_col + matrix_spacing, number_format='0')
                
                matrix_current_row += len(cross_tab['class_of_sku_matrix']) + 3
            
            # 2. Volume matrices side-by-side: Volume (#) on left, Volume% on right
            if 'volume_abs_matrix' in cross_tab and 'volume_percent_matrix' in cross_tab:
                # Left: Volume (#) - Absolute volume
                self._write_matrix_with_title(writer, 'ABC_FMS_Analysis', 
                                            "Volume (#)", 
                                            cross_tab['volume_abs_matrix'], 
                                            matrix_current_row, matrix_start_col, number_format='0')
                
                # Right: Volume% - Volume percentages
                self._write_matrix_with_title(writer, 'ABC_FMS_Analysis', 
                                            "Volume%", 
                                            cross_tab['volume_percent_matrix'], 
                                            matrix_current_row, matrix_start_col + matrix_spacing, number_format='0')
                
                matrix_current_row += len(cross_tab['volume_abs_matrix']) + 3
            
            # 3. Lines matrices side-by-side: Lines (#) on left, Lines% on right
            if 'lines_abs_matrix' in cross_tab and 'lines_percent_matrix' in cross_tab:
                # Left: Lines (#) - Absolute line counts
                self._write_matrix_with_title(writer, 'ABC_FMS_Analysis', 
                                            "Lines (#)", 
                                            cross_tab['lines_abs_matrix'], 
                                            matrix_current_row, matrix_start_col, number_format='0')
                
                # Right: Lines% - Line percentages
                self._write_matrix_with_title(writer, 'ABC_FMS_Analysis', 
                                            "Lines%", 
                                            cross_tab['lines_percent_matrix'], 
                                            matrix_current_row, matrix_start_col + matrix_spacing, number_format='0')
                
                matrix_current_row += len(cross_tab['lines_abs_matrix']) + 3
        
        # âœ… NEW: SKU Profile - Category Level Details (below the side-by-side matrices)
        if 'category_sku_matrix' in cross_tab and 'category_volume_pct_matrix' in cross_tab and 'category_lines_pct_matrix' in cross_tab:
            category_start_row = matrix_current_row + 2
            
            # Add section header
            section_header_df = pd.DataFrame([['SKU Profile - Category Level Details']], columns=[''])
            section_header_df.to_excel(writer, sheet_name='ABC_FMS_Analysis', 
                                     startrow=category_start_row, 
                                     startcol=matrix_start_col, 
                                     index=False, header=False)
            
            category_start_row += 2
            
            # 1. # SKUs table - SKU count by Category vs ABC-FMS Segment
            self._write_matrix_with_title(writer, 'ABC_FMS_Analysis',
                                         "# SKUs",
                                         cross_tab['category_sku_matrix'],
                                         category_start_row, matrix_start_col, number_format='0')
            
            category_start_row += len(cross_tab['category_sku_matrix']) + 4
            
            # 2. Cases % table - Volume percentage by Category vs ABC-FMS Segment
            self._write_matrix_with_title(writer, 'ABC_FMS_Analysis',
                                         "Cases %",
                                         cross_tab['category_volume_pct_matrix'],
                                         category_start_row, matrix_start_col, number_format='0')
            
            category_start_row += len(cross_tab['category_volume_pct_matrix']) + 4
            
            # 3. Lines % table - Order lines percentage by Category vs ABC-FMS Segment
            self._write_matrix_with_title(writer, 'ABC_FMS_Analysis',
                                         "Lines %",
                                         cross_tab['category_lines_pct_matrix'],
                                         category_start_row, matrix_start_col, number_format='0')
            
            matrix_current_row = category_start_row + len(cross_tab['category_lines_pct_matrix']) + 3
        
        # Continue with other sections below the SKU classifications
        current_row = len(sku_df_limited) + 5 if sku_df_limited is not None else matrix_current_row + 3
        
        # Detailed segment analysis
        if 'segment_details' in cross_tab:
            segment_df = cross_tab['segment_details']
            self._write_dataframe_with_title(writer, 'ABC_FMS_Analysis', 
                                           "Segment Details", 
                                           segment_df, 
                                           current_row, 0)
            current_row += len(segment_df) + 3
        
        # Strategic recommendations
        strategic_recs = abc_results.get('strategic_recommendations', {})
        if 'recommendations' in strategic_recs:
            recs_data = []
            for rec in strategic_recs['recommendations']:
                recs_data.append([
                    rec.get('segment', ''),
                    rec.get('priority', ''),
                    rec.get('recommendation', ''),
                    ', '.join(rec.get('actions', []))
                ])
            
            if recs_data:
                recs_df = pd.DataFrame(recs_data, columns=['Segment', 'Priority', 'Recommendation', 'Actions'])
                self._write_dataframe_with_title(writer, 'ABC_FMS_Analysis', 
                                               "Strategic Recommendations", 
                                               recs_df, 
                                               current_row, 0)
    
    def _write_matrix_with_title(self, writer, sheet_name, title, matrix, start_row, start_col, number_format='0.00'):
        """Write a matrix with a title using simple DataFrame approach"""
        
        # Create title row
        title_df = pd.DataFrame([[title]], columns=[''])
        title_df.to_excel(writer, sheet_name=sheet_name, startrow=start_row, 
                         startcol=start_col, index=False, header=False)
        
        # Write matrix with index and header  
        matrix.to_excel(writer, sheet_name=sheet_name, startrow=start_row + 2, 
                       startcol=start_col, index=True)
    
    def _write_dataframe_with_title(self, writer, sheet_name, title, df, start_row, start_col):
        """Write a dataframe with a title using simple DataFrame approach"""
        
        # Create title row
        title_df = pd.DataFrame([[title]], columns=[''])
        title_df.to_excel(writer, sheet_name=sheet_name, startrow=start_row, 
                         startcol=start_col, index=False, header=False)
        
        # Write dataframe starting from next row
        df.to_excel(writer, sheet_name=sheet_name, startrow=start_row + 2, 
                   startcol=start_col, index=False)
    
    def _create_inventory_analysis_sheet(self, writer):
        """Create inventory analysis sheet with SKU matrix and daily summary"""
        if 'inventory_analysis' not in self.analysis_results:
            # Create placeholder if no inventory analysis results
            if self.verbose:
                print("Creating Inventory Analysis sheet (no data available)...")
            placeholder_df = pd.DataFrame([
                ['Inventory Analysis', 'No inventory data available'],
                ['Status', 'Please ensure InventoryData sheet is present in uploaded file']
            ], columns=['Item', 'Value'])
            placeholder_df.to_excel(writer, sheet_name='Inventory_Analysis', index=False)
            return
        
        if self.verbose:
            print("Creating Inventory Analysis sheet...")
        
        inventory_results = self.analysis_results['inventory_analysis']
        
        # Get the SKU inventory matrix and daily summary
        sku_matrix = inventory_results.get('sku_inventory_matrix')
        daily_summary = inventory_results.get('daily_summary')
        
        if sku_matrix is not None and not sku_matrix.empty:
            # Write SKU inventory matrix (main table on left)
            sku_matrix.to_excel(writer, sheet_name='Inventory_Analysis', 
                              startrow=0, startcol=0, index=False)
            
            # Calculate position for daily summary table (to the right)
            # Add 2 columns of spacing after the SKU matrix
            right_col_start = len(sku_matrix.columns) + 2
            
            if daily_summary is not None and not daily_summary.empty:
                # Write daily summary table to the right
                daily_summary.to_excel(writer, sheet_name='Inventory_Analysis',
                                     startrow=0, startcol=right_col_start, index=False)
                
                if self.verbose:
                    print(f"  Created inventory analysis with {len(sku_matrix)} SKUs")
                    print(f"  Daily summary placed at column {right_col_start}")
        else:
            # No inventory data to display
            if self.verbose:
                print("  No inventory matrix data available")
            placeholder_df = pd.DataFrame([
                ['Inventory Analysis', 'No data to display'],
                ['Note', 'Inventory data may be missing or filtered out']
            ], columns=['Item', 'Value'])
            placeholder_df.to_excel(writer, sheet_name='Inventory_Analysis', index=False)
    
    def _create_manpower_analysis_sheet(self, writer):
        """Create manpower analysis sheet with placeholder data"""
        if 'manpower_analysis' not in self.analysis_results:
            # Create placeholder if no manpower analysis results
            if self.verbose:
                print("Creating Manpower Analysis sheet (no data available)...")
            placeholder_df = pd.DataFrame([
                ['Manpower Analysis', 'No analysis performed'],
                ['Status', 'Order or receipt data required for manpower analysis'],
                ['Implementation', 'Placeholder - full implementation pending']
            ], columns=['Item', 'Value'])
            placeholder_df.to_excel(writer, sheet_name='Manpower_Analysis', index=False)
            return
        
        if self.verbose:
            print("Creating Manpower Analysis sheet...")
        
        manpower_results = self.analysis_results['manpower_analysis']
        current_row = 0
        
        # Section 1: Picking Analysis
        picking_analysis = manpower_results.get('picking_analysis', {})
        if picking_analysis:
            # Add section header
            header_df = pd.DataFrame([['PICKING MANPOWER ANALYSIS']], columns=['Section'])
            header_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False, header=False)
            current_row += 2
            
            # Create picking analysis data
            picking_data = []
            for key, value in picking_analysis.items():
                if key != 'notes':
                    picking_data.append([key.replace('_', ' ').title(), str(value)])
            
            if picking_data:
                picking_df = pd.DataFrame(picking_data, columns=['Metric', 'Value'])
                picking_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False)
                current_row += len(picking_df) + 3
        
        # Section 2: Receiving Analysis
        receiving_analysis = manpower_results.get('receiving_analysis', {})
        if receiving_analysis:
            # Add section header
            header_df = pd.DataFrame([['RECEIVING & PUTAWAY MANPOWER ANALYSIS']], columns=['Section'])
            header_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False, header=False)
            current_row += 2
            
            # Create receiving analysis data
            receiving_data = []
            for key, value in receiving_analysis.items():
                if key != 'notes':
                    receiving_data.append([key.replace('_', ' ').title(), str(value)])
            
            if receiving_data:
                receiving_df = pd.DataFrame(receiving_data, columns=['Metric', 'Value'])
                receiving_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False)
                current_row += len(receiving_df) + 3
        
        # Section 3: Loading Analysis
        loading_analysis = manpower_results.get('loading_analysis', {})
        if loading_analysis:
            # Add section header
            header_df = pd.DataFrame([['LOADING MANPOWER ANALYSIS']], columns=['Section'])
            header_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False, header=False)
            current_row += 2
            
            # Create loading analysis data
            loading_data = []
            for key, value in loading_analysis.items():
                if key != 'notes':
                    loading_data.append([key.replace('_', ' ').title(), str(value)])
            
            if loading_data:
                loading_df = pd.DataFrame(loading_data, columns=['Metric', 'Value'])
                loading_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False)
                current_row += len(loading_df) + 3
        
        # Section 4: Efficiency Summary
        efficiency_summary = manpower_results.get('efficiency_summary', {})
        if efficiency_summary:
            # Add section header
            header_df = pd.DataFrame([['EFFICIENCY SUMMARY & RECOMMENDATIONS']], columns=['Section'])
            header_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False, header=False)
            current_row += 2
            
            # Create efficiency summary data
            efficiency_data = []
            for key, value in efficiency_summary.items():
                if key not in ['optimization_opportunities', 'cost_analysis', 'notes']:
                    efficiency_data.append([key.replace('_', ' ').title(), str(value)])
            
            if efficiency_data:
                efficiency_df = pd.DataFrame(efficiency_data, columns=['Metric', 'Value'])
                efficiency_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False)
                current_row += len(efficiency_df) + 2
            
            # Add optimization opportunities
            if 'optimization_opportunities' in efficiency_summary:
                header_df = pd.DataFrame([['OPTIMIZATION OPPORTUNITIES']], columns=['Section'])
                header_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False, header=False)
                current_row += 2
                
                opportunities = efficiency_summary['optimization_opportunities']
                if opportunities:
                    opp_data = [[f"{i+1}. {opp}"] for i, opp in enumerate(opportunities)]
                    opp_df = pd.DataFrame(opp_data, columns=['Recommendations'])
                    opp_df.to_excel(writer, sheet_name='Manpower_Analysis', startrow=current_row, index=False)
    
    def _create_receipt_analysis_sheet(self, writer):
        """Create receipt analysis sheet - daily patterns with percentile analysis on the right"""
        if 'receipt_analysis' not in self.analysis_results:
            return
        
        if self.verbose:
            print("Creating Receipt Analysis sheet...")
        
        receipt_results = self.analysis_results['receipt_analysis']
        
        # Daily patterns on the left
        daily_patterns = receipt_results.get('daily_patterns', {})
        if 'daily_data' in daily_patterns:
            daily_df = daily_patterns['daily_data']
            daily_df.to_excel(writer, sheet_name='Receipt_Analysis', startrow=0, startcol=0, index=False)
            
            # Add receipt charts
            from charts.excel_chart_generator import ExcelChartGenerator
            chart_gen = ExcelChartGenerator(writer.sheets['Receipt_Analysis'])
            
            table_pos = {
                'row': 1,  # Excel uses 1-based indexing
                'col': 1,
                'num_rows': len(daily_df),
                'num_cols': len(daily_df.columns)
            }
            
            # Add main receipt trend chart (Lines, Shipments, Trucks)
            chart_gen.add_receipt_daily_trend_chart(table_pos)
            
            # Add volume trend chart below the first chart
            chart_gen.add_receipt_volume_trend_chart(table_pos)
            
            # Calculate the right column position (after daily patterns table + some spacing)
            right_col_start = len(daily_df.columns) + 2
            
            # Percentile Analysis on the right
            percentile_analysis = receipt_results.get('percentile_analysis', {})
            if percentile_analysis:
                current_row = 0
                
                # Header for percentile analysis
                perc_header = pd.DataFrame([['RECEIPT PERCENTILE ANALYSIS']], columns=['Header'])
                perc_header.to_excel(writer, sheet_name='Receipt_Analysis', startrow=current_row, startcol=right_col_start, index=False, header=False)
                current_row += 2
                
                # Column headers for percentile table
                headers = pd.DataFrame([['Percentile', '#Trucks', '#Shipments', '#Lines', '#SKUs', '#Cases']], 
                                     columns=['Percentile', '#Trucks', '#Shipments', '#Lines', '#SKUs', '#Cases'])
                headers.to_excel(writer, sheet_name='Receipt_Analysis', startrow=current_row, startcol=right_col_start, index=False, header=False)
                current_row += 1
                
                # Get horizontal percentile data
                horizontal_percentiles = percentile_analysis.get('horizontal_percentiles', {})
                
                if horizontal_percentiles:
                    percentile_data = []
                    
                    # Build row order from available percentiles
                    row_order = []
                    if 'Max' in horizontal_percentiles:
                        row_order.append('Max')
                    
                    # Add all configured percentiles in descending order
                    percentile_keys = [k for k in horizontal_percentiles.keys() if k.endswith('%ile')]
                    percentile_keys.sort(key=lambda x: float(x.replace('%ile', '')), reverse=True)
                    row_order.extend(percentile_keys)
                    
                    for percentile_name in row_order:
                        if percentile_name in horizontal_percentiles:
                            row_data = horizontal_percentiles[percentile_name]
                            percentile_data.append([
                                percentile_name,
                                int(row_data.get('#Trucks', 0)),
                                int(row_data.get('#Shipments', 0)), 
                                int(row_data.get('#Lines', 0)),
                                int(row_data.get('#SKUs', 0)),
                                int(row_data.get('#Cases', 0))
                            ])
                    
                    perc_df = pd.DataFrame(percentile_data, columns=['Percentile', '#Trucks', '#Shipments', '#Lines', '#SKUs', '#Cases'])
                    perc_df.to_excel(writer, sheet_name='Receipt_Analysis', startrow=current_row, startcol=right_col_start, index=False, header=False)
    
    def _create_recommendations_sheet(self, writer):
        """Create consolidated recommendations sheet"""
        if self.verbose:
            print("Creating Recommendations sheet...")
        
        all_recommendations = []
        
        # Collect recommendations from all analyses
        analysis_modules = ['order_analysis', 'sku_analysis', 'abc_fms_analysis', 'receipt_analysis']
        
        for module in analysis_modules:
            if module in self.analysis_results:
                module_results = self.analysis_results[module]
                
                # Check for recommendations in different possible locations
                recommendations = None
                if 'recommendations' in module_results:
                    recs_data = module_results['recommendations']
                    if isinstance(recs_data, dict) and 'recommendations' in recs_data:
                        recommendations = recs_data['recommendations']
                    elif isinstance(recs_data, list):
                        recommendations = recs_data
                
                # Also check for strategic recommendations
                if 'strategic_recommendations' in module_results:
                    strategic_recs = module_results['strategic_recommendations']
                    if isinstance(strategic_recs, dict) and 'recommendations' in strategic_recs:
                        strategic_recommendations = strategic_recs['recommendations']
                        if recommendations:
                            recommendations.extend(strategic_recommendations)
                        else:
                            recommendations = strategic_recommendations
                
                if recommendations:
                    for rec in recommendations:
                        all_recommendations.append([
                            module.replace('_', ' ').title(),
                            rec.get('category', rec.get('segment', 'General')),
                            rec.get('priority', 'Medium'),
                            rec.get('recommendation', ''),
                            rec.get('impact', rec.get('actions', ''))
                        ])
        
        if all_recommendations:
            recs_df = pd.DataFrame(all_recommendations, 
                                 columns=['Analysis Module', 'Category', 'Priority', 'Recommendation', 'Expected Impact'])
            
            # Sort by priority
            priority_order = {'Critical': 1, 'High': 2, 'Medium': 3, 'Low': 4}
            recs_df['Priority_Order'] = recs_df['Priority'].map(priority_order).fillna(5)
            recs_df = recs_df.sort_values('Priority_Order').drop('Priority_Order', axis=1)
            
            recs_df.to_excel(writer, sheet_name='Recommendations', index=False)
        else:
            # Create placeholder if no recommendations found
            placeholder_df = pd.DataFrame([['No recommendations available', '', '', '', '']], 
                                        columns=['Analysis Module', 'Category', 'Priority', 'Recommendation', 'Expected Impact'])
            placeholder_df.to_excel(writer, sheet_name='Recommendations', index=False)
    
    def _create_configuration_sheet(self, writer):
        """Create configuration documentation sheet"""
        if self.verbose:
            print("Creating Configuration sheet...")
        
        config_data = []
        
        # Analysis configuration
        config_data.append(['ANALYSIS CONFIGURATION', ''])
        config_data.append(['Configuration Generated', datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
        config_data.append(['', ''])
        
        if self.configuration:
            for category, settings in self.configuration.items():
                config_data.append([f'{category.upper().replace("_", " ")}', ''])
                if isinstance(settings, dict):
                    for key, value in settings.items():
                        config_data.append([key.replace('_', ' ').title(), str(value)])
                else:
                    config_data.append(['Value', str(settings)])
                config_data.append(['', ''])
        
        # Add default settings from config module
        config_data.append(['DEFAULT SETTINGS', ''])
        config_data.append(['ABC A Threshold', f"{config.DEFAULT_ABC_THRESHOLDS['A_THRESHOLD']}%"])
        config_data.append(['ABC B Threshold', f"{config.DEFAULT_ABC_THRESHOLDS['B_THRESHOLD']}%"])
        config_data.append(['FMS Fast Threshold', f"{config.DEFAULT_FMS_THRESHOLDS['F_THRESHOLD']}%"])
        config_data.append(['FMS Medium Threshold', f"{config.DEFAULT_FMS_THRESHOLDS['M_THRESHOLD']}%"])
        config_data.append(['Default Percentiles', ', '.join(map(str, config.DEFAULT_PERCENTILE_LEVELS))])
        
        config_df = pd.DataFrame(config_data, columns=['Setting', 'Value'])
        config_df.to_excel(writer, sheet_name='Configuration', index=False)
    
    def _create_raw_data_summary(self, writer):
        """Create raw data summary sheet"""
        if self.verbose:
            print("Creating Raw Data Summary sheet...")
        
        summary_data = []
        
        # Data source information
        summary_data.append(['RAW DATA SUMMARY', ''])
        summary_data.append(['Report Generated', datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
        summary_data.append(['Tool Version', 'Warehouse Analysis Tool V2'])
        summary_data.append(['', ''])
        
        # Data availability summary
        if 'data_loader' in self.analysis_results:
            data_results = self.analysis_results['data_loader']
            
            summary_data.append(['DATA AVAILABILITY', ''])
            
            for data_type, data_info in data_results.get('data', {}).items():
                if isinstance(data_info, pd.DataFrame):
                    summary_data.append([data_type.replace('_', ' ').title(), f'{len(data_info)} records'])
                else:
                    summary_data.append([data_type.replace('_', ' ').title(), 'Available'])
            
            summary_data.append(['', ''])
            
            # Validation results
            validation_results = data_results.get('validation', {})
            if validation_results:
                summary_data.append(['DATA VALIDATION', ''])
                for data_type, validation in validation_results.items():
                    if isinstance(validation, dict):
                        summary_data.append([f'{data_type.replace("_", " ").title()} - Total Rows', validation.get('total_rows', 'N/A')])
                        summary_data.append([f'{data_type.replace("_", " ").title()} - Date Range (Days)', validation.get('date_range_days', 'N/A')])
        
        # Analysis modules executed
        summary_data.append(['', ''])
        summary_data.append(['ANALYSIS MODULES EXECUTED', ''])
        
        executed_modules = [key for key in self.analysis_results.keys() if key != 'data_loader']
        for module in executed_modules:
            summary_data.append([module.replace('_', ' ').title(), 'Completed'])
        
        summary_df = pd.DataFrame(summary_data, columns=['Item', 'Value'])
        summary_df.to_excel(writer, sheet_name='Raw_Data_Summary', index=False)
    
# Test function for standalone execution
if __name__ == "__main__":
    print("ExcelGenerator module - ready for use")
    print("This module requires analysis results to function.")
    print("Use within the main analysis pipeline for proper functionality.")