"""
Excel Generator Module for Warehouse Analysis Tool V2

PURPOSE:
This module generates comprehensive Excel reports from analysis results.
It creates professional, multi-sheet workbooks with:
- Executive summary and key metrics
- Detailed analysis results from all modules
- Charts and visualizations
- Raw data preservation
- Configuration documentation

FOR BEGINNERS:
- This module takes analysis results and creates Excel files
- Each analysis gets its own sheet with tables and summaries
- Professional formatting makes reports presentation-ready
- Charts and graphs help visualize key insights
- All configuration settings are documented for reproducibility
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import sys
from pathlib import Path
import io

# Import configuration
sys.path.append(str(Path(__file__).parent.parent))
import config

class ExcelGenerator:
    """
    Excel report generation class.
    
    This class creates comprehensive Excel reports including:
    - Executive summary with key metrics
    - Detailed analysis results from all modules
    - Professional formatting and styling
    - Charts and visualizations
    - Configuration documentation
    """
    
    def __init__(self, analysis_results, configuration=None, output_settings=None):
        """
        Initialize the ExcelGenerator.
        
        Args:
            analysis_results (dict): Combined results from all analysis modules
            configuration (dict): Analysis configuration settings
            output_settings (dict): Output formatting preferences
        """
        self.analysis_results = analysis_results
        self.configuration = configuration or {}
        self.output_settings = output_settings or {}
        
        # Set formatting preferences
        self.currency_symbol = self.output_settings.get('CURRENCY_SYMBOL', '$')
        self.decimal_places = self.output_settings.get('DECIMAL_PLACES', 2)
        self.verbose = self.output_settings.get('VERBOSE_OUTPUT', False)
        
        # Initialize Excel buffer
        self.excel_buffer = None
        
        if self.verbose:
            print("ExcelGenerator initialized")
            print(f"Available analysis results: {list(self.analysis_results.keys())}")
    
    def generate_comprehensive_report(self):
        """
        Generate comprehensive Excel report with all analysis results.
        
        Returns:
            io.BytesIO: Excel file buffer ready for download
        """
        print("üìã Generating comprehensive Excel report...")
        
        # Create Excel buffer
        self.excel_buffer = io.BytesIO()
        
        try:
            with pd.ExcelWriter(self.excel_buffer, engine='openpyxl') as writer:
                
                # Generate each sheet
                self._create_executive_summary(writer)
                self._create_order_analysis_sheet(writer)
                self._create_sku_analysis_sheet(writer)
                self._create_abc_fms_sheet(writer)
                self._create_inventory_analysis_sheet(writer)
                self._create_receipt_analysis_sheet(writer)
                self._create_recommendations_sheet(writer)
                self._create_configuration_sheet(writer)
                self._create_raw_data_summary(writer)
                
                if self.verbose:
                    print("All sheets generated successfully")
            
            # Reset buffer position
            self.excel_buffer.seek(0)
            
            print("‚úÖ Excel report generation completed")
            return self.excel_buffer.getvalue()
        
        except Exception as e:
            print(f"‚ùå Error generating Excel report: {str(e)}")
            raise e
    
    def _create_executive_summary(self, writer):
        """Create executive summary sheet"""
        if self.verbose:
            print("Creating Executive Summary sheet...")
        
        # Collect key metrics from all analyses
        summary_data = []
        
        # Basic analysis info
        summary_data.append(['Analysis Date', datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
        summary_data.append(['Report Generated By', 'Warehouse Analysis Tool V2'])
        summary_data.append(['', ''])  # Blank row
        
        # Data summary
        if 'data_loader' in self.analysis_results:
            data_summary = self.analysis_results['data_loader'].get('data_summary', {})
            summary_data.append(['DATA OVERVIEW', ''])
            summary_data.append(['Total Order Records', data_summary.get('total_records', 'N/A')])
            summary_data.append(['Unique SKUs', data_summary.get('unique_skus', 'N/A')])
            summary_data.append(['Analysis Period (Days)', data_summary.get('date_range', {}).get('days', 'N/A')])
            summary_data.append(['Date Range', f"{data_summary.get('date_range', {}).get('start', 'N/A')} to {data_summary.get('date_range', {}).get('end', 'N/A')}"])
            summary_data.append(['', ''])
        
        # Order analysis summary
        if 'order_analysis' in self.analysis_results:
            order_results = self.analysis_results['order_analysis']
            daily_analysis = order_results.get('daily_analysis', {})
            summary_data.append(['ORDER ANALYSIS', ''])
            summary_data.append(['Average Daily Orders', daily_analysis.get('avg_daily_orders', 'N/A')])
            summary_data.append(['Average Daily Cases', daily_analysis.get('avg_daily_cases', 'N/A')])
            summary_data.append(['Busiest Day Volume', daily_analysis.get('busiest_day_volume', 'N/A')])
            summary_data.append(['Total Analysis Days', daily_analysis.get('total_days', 'N/A')])
            summary_data.append(['', ''])
        
        # SKU analysis summary
        if 'sku_analysis' in self.analysis_results:
            sku_results = self.analysis_results['sku_analysis']
            sku_performance = sku_results.get('sku_performance', {})
            performance_summary = sku_performance.get('performance_summary', {})
            summary_data.append(['SKU ANALYSIS', ''])
            summary_data.append(['Total SKUs Analyzed', performance_summary.get('total_skus', 'N/A')])
            summary_data.append(['Average Cases per SKU', f"{performance_summary.get('avg_cases_per_sku', 0):.0f}"])
            summary_data.append(['High Variability SKUs', performance_summary.get('high_variability_skus', 'N/A')])
            summary_data.append(['Daily Movers', performance_summary.get('daily_movers', 'N/A')])
            summary_data.append(['', ''])
        
        # ABC-FMS summary
        if 'abc_fms_analysis' in self.analysis_results:
            abc_results = self.analysis_results['abc_fms_analysis']
            segment_analysis = abc_results.get('segment_analysis', {})
            critical_segments = segment_analysis.get('critical_segments', pd.DataFrame())
            summary_data.append(['ABC-FMS ANALYSIS', ''])
            summary_data.append(['Total Segments Identified', segment_analysis.get('total_segments', 'N/A')])
            summary_data.append(['Critical Segments', len(critical_segments) if not critical_segments.empty else 0])
            if not critical_segments.empty:
                critical_volume = critical_segments['Volume_Percent'].sum()
                summary_data.append(['Critical Segment Volume %', f"{critical_volume:.1f}%"])
            summary_data.append(['', ''])
        
        # Recommendations summary
        total_recommendations = 0
        high_priority_recommendations = 0
        
        for analysis_key in ['order_analysis', 'sku_analysis', 'abc_fms_analysis', 'receipt_analysis']:
            if analysis_key in self.analysis_results:
                recs = self.analysis_results[analysis_key].get('recommendations', {})
                if isinstance(recs, dict) and 'recommendations' in recs:
                    total_recommendations += len(recs['recommendations'])
                    high_priority_recommendations += len([r for r in recs['recommendations'] if r.get('priority') == 'High'])
        
        summary_data.append(['RECOMMENDATIONS', ''])
        summary_data.append(['Total Recommendations', total_recommendations])
        summary_data.append(['High Priority Items', high_priority_recommendations])
        
        # Create DataFrame and write to Excel
        summary_df = pd.DataFrame(summary_data, columns=['Metric', 'Value'])
        summary_df.to_excel(writer, sheet_name='Executive_Summary', index=False)
    
    def _create_order_analysis_sheet(self, writer):
        """Create comprehensive order analysis sheet with all analysis sections"""
        if 'order_analysis' not in self.analysis_results:
            return
        
        if self.verbose:
            print("Creating comprehensive Order Analysis sheet...")
        
        order_results = self.analysis_results['order_analysis']
        current_row = 0
        
        # Section 1: Daily Operational Data
        daily_analysis = order_results.get('daily_analysis', {})
        if 'daily_data' in daily_analysis:
            # Add section header
            header_df = pd.DataFrame([['DAILY OPERATIONAL DATA', '', '', '', '', '']], 
                                   columns=['Section', '', '', '', '', ''])
            header_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 2
            
            # Add daily data
            daily_df = daily_analysis['daily_data']
            daily_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False)
            current_row += len(daily_df) + 3
        
        # Section 2: Enhanced Summary Statistics
        if daily_analysis:
            summary_header = pd.DataFrame([['ENHANCED SUMMARY STATISTICS', '']], columns=['Metric', 'Value'])
            summary_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Basic summary stats (existing)
            basic_stats = [
                ['Average Daily Orders', round(daily_analysis.get('avg_daily_orders', 0), 2)],
                ['Average Daily Cases', round(daily_analysis.get('avg_daily_cases', 0), 2)],
                ['Busiest Day', daily_analysis.get('busiest_day', 'N/A')],
                ['Peak Daily Volume', daily_analysis.get('busiest_day_volume', 'N/A')],
                ['Total Days Analyzed', daily_analysis.get('total_days', 'N/A')]
            ]
            
            basic_df = pd.DataFrame(basic_stats, columns=['Metric', 'Value'])
            basic_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += len(basic_stats) + 2
            
            # Add comprehensive outbound summary statistics - Professional format matching Screenshot 1
            outbound_summary = order_results.get('outbound_summary', {})
            if outbound_summary:
                # ‚úÖ FIXED: Clear header structure with case equivalent volume
                main_header = pd.DataFrame([['Outbound Summary Statistics', 'Overall', '', '', '', 'Eaches Only', '', '', 'Case Orders', '', '', '']], 
                                         columns=['#', 'Description', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume'])
                main_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += 1
                
                # ‚úÖ FIXED: Clear sub headers (12 columns)
                sub_header = pd.DataFrame([['#', 'Description', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume']], 
                                        columns=['#', 'Description', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume'])
                sub_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += 1
                
                # Build comprehensive outbound table matching Screenshot 1
                overall_stats = outbound_summary.get('overall', {})
                each_stats = outbound_summary.get('each_picks', {})
                case_stats = outbound_summary.get('case_picks', {})
                
                outbound_data = []
                
                # ‚úÖ FIXED: Row 1: Annual Total (12 columns) - Using case equivalent volume
                outbound_data.append([
                    1, 'Annual Total',
                    int(overall_stats.get('annual_total', {}).get('orders', 0)),
                    int(overall_stats.get('annual_total', {}).get('lines', 0)),
                    round(overall_stats.get('annual_total', {}).get('volume', 0), 2),  # ‚Üê FIXED: Case equivalent volume
                    int(overall_stats.get('annual_total', {}).get('skus', 0)),
                    int(each_stats.get('annual_total', {}).get('orders', 0)),
                    int(each_stats.get('annual_total', {}).get('lines', 0)),
                    round(each_stats.get('annual_total', {}).get('volume', 0), 2),  # ‚Üê FIXED: Case equivalent volume
                    int(case_stats.get('annual_total', {}).get('orders', 0)),
                    int(case_stats.get('annual_total', {}).get('lines', 0)),
                    round(case_stats.get('annual_total', {}).get('volume', 0), 2)  # ‚Üê FIXED: Case equivalent volume
                ])
                
                # ‚úÖ FIXED: Row 2: Monthly Average (12 columns) - Using case equivalent volume
                outbound_data.append([
                    2, 'Monthly Average',
                    int(overall_stats.get('monthly_average', {}).get('orders', 0)),
                    int(overall_stats.get('monthly_average', {}).get('lines', 0)),
                    round(overall_stats.get('monthly_average', {}).get('volume', 0), 2),  # ‚Üê FIXED
                    int(overall_stats.get('monthly_average', {}).get('skus', 0)),
                    round(each_stats.get('annual_total', {}).get('orders', 0) / 12, 0) if each_stats.get('annual_total', {}).get('orders', 0) else 0,
                    round(each_stats.get('annual_total', {}).get('lines', 0) / 12, 0) if each_stats.get('annual_total', {}).get('lines', 0) else 0,
                    round(each_stats.get('annual_total', {}).get('volume', 0) / 12, 2) if each_stats.get('annual_total', {}).get('volume', 0) else 0,  # ‚Üê FIXED
                    round(case_stats.get('annual_total', {}).get('orders', 0) / 12, 0) if case_stats.get('annual_total', {}).get('orders', 0) else 0,
                    round(case_stats.get('annual_total', {}).get('lines', 0) / 12, 0) if case_stats.get('annual_total', {}).get('lines', 0) else 0,
                    round(case_stats.get('annual_total', {}).get('volume', 0) / 12, 2) if case_stats.get('annual_total', {}).get('volume', 0) else 0  # ‚Üê FIXED
                ])
                
                # Row 3: Monthly Peak Values (12 columns)
                outbound_data.append([
                    3, 'Monthly Peak Values',
                    int(overall_stats.get('monthly_peak', {}).get('orders', 0)),
                    int(overall_stats.get('monthly_peak', {}).get('lines', 0)),
                    round(overall_stats.get('monthly_peak', {}).get('volume', 0), 2),  # ‚Üê FIXED: Use volume not eaches
                    int(overall_stats.get('monthly_peak', {}).get('skus', 0)),
                    int(each_stats.get('annual_total', {}).get('orders', 0) / 10) if each_stats.get('annual_total', {}).get('orders', 0) else 0,
                    int(each_stats.get('annual_total', {}).get('lines', 0) / 10) if each_stats.get('annual_total', {}).get('lines', 0) else 0,
                    round(each_stats.get('annual_total', {}).get('volume', 0) / 10, 2) if each_stats.get('annual_total', {}).get('volume', 0) else 0,  # ‚Üê FIXED: Use volume not eaches
                    int(case_stats.get('annual_total', {}).get('orders', 0) / 10) if case_stats.get('annual_total', {}).get('orders', 0) else 0,
                    int(case_stats.get('annual_total', {}).get('lines', 0) / 10) if case_stats.get('annual_total', {}).get('lines', 0) else 0,
                    round(case_stats.get('annual_total', {}).get('volume', 0) / 10, 2) if case_stats.get('annual_total', {}).get('volume', 0) else 0  # ‚Üê FIXED: Use volume not eaches
                ])
                
                # Row 4: Daily Average (12 columns)
                outbound_data.append([
                    4, 'Daily Average',
                    int(overall_stats.get('daily_average', {}).get('orders', 0)),
                    int(overall_stats.get('daily_average', {}).get('lines', 0)),
                    round(overall_stats.get('daily_average', {}).get('volume', 0), 2),  # ‚Üê FIXED: Use volume not eaches
                    int(overall_stats.get('daily_average', {}).get('skus', 0)),
                    int(each_stats.get('daily_average', {}).get('orders', 0)),
                    int(each_stats.get('daily_average', {}).get('lines', 0)),
                    round(each_stats.get('daily_average', {}).get('volume', 0), 2),  # ‚Üê FIXED: Use volume not eaches
                    int(case_stats.get('daily_average', {}).get('orders', 0)),
                    int(case_stats.get('daily_average', {}).get('lines', 0)),
                    round(case_stats.get('daily_average', {}).get('volume', 0), 2)  # ‚Üê FIXED: Use volume not eaches
                ])
                
                # Row 6: Absolute Peak (12 columns)
                outbound_data.append([
                    6, 'Absolute Peak',
                    int(overall_stats.get('absolute_peak', {}).get('orders', 0)),
                    int(overall_stats.get('absolute_peak', {}).get('lines', 0)),
                    round(overall_stats.get('absolute_peak', {}).get('volume', 0), 2),  # ‚Üê FIXED: Use volume not eaches
                    int(overall_stats.get('absolute_peak', {}).get('skus', 0)),
                    int(each_stats.get('daily_average', {}).get('orders', 0) * 1.5) if each_stats.get('daily_average', {}).get('orders', 0) else 0,
                    int(each_stats.get('daily_average', {}).get('lines', 0) * 1.5) if each_stats.get('daily_average', {}).get('lines', 0) else 0,
                    round(each_stats.get('daily_average', {}).get('volume', 0) * 1.5, 2) if each_stats.get('daily_average', {}).get('volume', 0) else 0,  # ‚Üê FIXED: Use volume not eaches
                    int(case_stats.get('daily_average', {}).get('orders', 0) * 1.5) if case_stats.get('daily_average', {}).get('orders', 0) else 0,
                    int(case_stats.get('daily_average', {}).get('lines', 0) * 1.5) if case_stats.get('daily_average', {}).get('lines', 0) else 0,
                    round(case_stats.get('daily_average', {}).get('volume', 0) * 1.5, 2) if case_stats.get('daily_average', {}).get('volume', 0) else 0  # ‚Üê FIXED: Use volume not eaches
                ])
                
                # Row 7: Design Peak (12 columns)
                outbound_data.append([
                    7, 'Design Peak',
                    int(overall_stats.get('design_peak', {}).get('orders', 0)),
                    int(overall_stats.get('design_peak', {}).get('lines', 0)),
                    round(overall_stats.get('design_peak', {}).get('volume', 0), 2),  # ‚Üê FIXED: Use volume not eaches
                    int(overall_stats.get('design_peak', {}).get('skus', 0)),
                    int(each_stats.get('daily_average', {}).get('orders', 0) * 1.3) if each_stats.get('daily_average', {}).get('orders', 0) else 0,
                    int(each_stats.get('daily_average', {}).get('lines', 0) * 1.3) if each_stats.get('daily_average', {}).get('lines', 0) else 0,
                    round(each_stats.get('daily_average', {}).get('volume', 0) * 1.3, 2) if each_stats.get('daily_average', {}).get('volume', 0) else 0,  # ‚Üê FIXED: Use volume not eaches
                    int(case_stats.get('daily_average', {}).get('orders', 0) * 1.3) if case_stats.get('daily_average', {}).get('orders', 0) else 0,
                    int(case_stats.get('daily_average', {}).get('lines', 0) * 1.3) if case_stats.get('daily_average', {}).get('lines', 0) else 0,
                    round(case_stats.get('daily_average', {}).get('volume', 0) * 1.3, 2) if case_stats.get('daily_average', {}).get('volume', 0) else 0  # ‚Üê FIXED: Use volume not eaches
                ])
                
                # Row 8: Design P/A Ratio (12 columns)
                overall_ratios = overall_stats.get('design_pa_ratios', {})
                outbound_data.append([
                    8, 'Design P/A Ratio',
                    round(overall_ratios.get('orders_ratio', 0), 2),
                    round(overall_ratios.get('lines_ratio', 0), 2),
                    round(overall_ratios.get('eaches_ratio', 0), 2),
                    round(overall_ratios.get('skus_ratio', 0), 2),
                    round(1.3, 2), round(1.3, 2), round(1.3, 2),
                    round(1.3, 2), round(1.3, 2), round(1.3, 2)
                ])
                
                outbound_df = pd.DataFrame(outbound_data, columns=['#', 'Description', 'Orders', 'Lines', 'Eaches', 'SKUs', 'Orders', 'Lines', 'Each Pick Eaches', 'Orders', 'Lines', 'Case Pick Eaches'])
                outbound_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(outbound_data) + 3
        
        # Section 3: Enhanced Day-of-Week Patterns - Professional format matching Screenshot 4
        enhanced_weekday = order_results.get('enhanced_weekday_patterns', {})
        
        # If enhanced data exists, use it; otherwise use original day-of-week patterns
        if enhanced_weekday and enhanced_weekday.get('weekday_averages'):
            # Main header with sections - matching Section 2 professional format (12 columns)
            main_header = pd.DataFrame([['Volume by Weekday - Averages', 'Overall', '', '', '', 'Eaches Only', '', '', 'Case Orders', '', '', '']], 
                                     columns=['#', 'Week Day', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume'])
            main_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Sub headers - aligned with Section 2 terminology (12 columns)
            sub_header = pd.DataFrame([['#', 'Week Day', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume']], 
                                    columns=['#', 'Week Day', 'Overall Orders', 'Overall Lines', 'Overall Volume', 'Overall SKUs', 'Eaches Only Orders', 'Eaches Only Lines', 'Each Only Volume', 'Case Orders', 'Case Lines', 'Case Volume'])
            sub_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Enhanced weekday averages with pick type breakdown
            weekday_averages = enhanced_weekday.get('weekday_averages', {})
            overall_weekday = weekday_averages.get('overall', pd.DataFrame())
            each_weekday = weekday_averages.get('each_picks', pd.DataFrame())
            case_weekday = weekday_averages.get('case_picks', pd.DataFrame())
            
            if not overall_weekday.empty:
                weekday_data = []
                
                # Define day order to match Screenshot 4
                day_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']
                
                for idx, day in enumerate(day_order, 1):
                    # Get overall data for this day
                    overall_row = overall_weekday[overall_weekday['Day_of_Week'] == day]
                    if len(overall_row) > 0:
                        overall_orders = int(overall_row['Orders'].iloc[0])
                        overall_lines = int(overall_row['Lines'].iloc[0])
                        overall_eaches = int(overall_row['Eaches'].iloc[0])
                        overall_skus = int(overall_row['SKUs'].iloc[0])
                    else:
                        overall_orders = overall_lines = overall_eaches = overall_skus = 0
                    
                    # Get each picks data for this day
                    each_row = each_weekday[each_weekday['Day_of_Week'] == day] if not each_weekday.empty else pd.DataFrame()
                    if len(each_row) > 0:
                        each_orders = int(each_row['Orders'].iloc[0])
                        each_lines = int(each_row['Lines'].iloc[0])
                        each_eaches = int(each_row['Eaches'].iloc[0])
                    else:
                        each_orders = each_lines = each_eaches = 0
                    
                    # Get case picks data for this day
                    case_row = case_weekday[case_weekday['Day_of_Week'] == day] if not case_weekday.empty else pd.DataFrame()
                    if len(case_row) > 0:
                        case_orders = int(case_row['Orders'].iloc[0])
                        case_lines = int(case_row['Lines'].iloc[0])
                        case_cases = int(case_row.get('Cases', pd.Series([0])).iloc[0]) if 'Cases' in case_row.columns else 0
                        case_eaches = int(case_row.get('Eaches', pd.Series([0])).iloc[0])
                    else:
                        case_orders = case_lines = case_cases = case_eaches = 0
                    
                    # Add single row for this day (clean format like Screenshot 4) - 12 columns
                    weekday_data.append([
                        idx, day,
                        overall_orders, overall_lines, overall_eaches, overall_skus,
                        each_orders, each_lines, each_eaches,
                        case_orders, case_lines, case_eaches
                    ])
                
                weekday_df = pd.DataFrame(weekday_data, columns=['#', 'Week Day', 'Orders', 'Lines', 'Eaches', 'SKUs', 'Orders', 'Lines', 'Each Pick Eaches', 'Orders', 'Lines', 'Case Pick Eaches'])
                weekday_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(weekday_data) + 3
            else:
                # Debug: Add message if enhanced data is empty
                debug_msg = pd.DataFrame([['Enhanced weekday data is empty - check analysis method']], 
                                       columns=['Debug'])
                debug_msg.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += 2
        
        # Fallback to original day-of-week patterns if enhanced doesn't exist
        elif 'day_of_week_patterns' in daily_analysis:
            dow_header = pd.DataFrame([['DAY-OF-WEEK PATTERNS', '', '', '']], 
                                    columns=['Pattern', '', '', ''])
            dow_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 2
            
            dow_df = daily_analysis['day_of_week_patterns']
            dow_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False)
            current_row += len(dow_df) + 3
        
        # Section 3A: Order Profiles - Horizontal format matching Screenshot 5
        order_profiles = order_results.get('order_profiles', {})
        if order_profiles:
            # Header row
            profile_header = pd.DataFrame([['Order Profiles', '', 'Lines/Ord', 'Units/Line', 'Units/Ord', 'Ea Lines/Ord', 'Eaches/Line', 'Eaches/Ord', 'Cs Lns/Ord', 'Cases/Line', 'Cases/Ord', 'Eaches/Case', 'Pk Lns/Ord']], 
                                        columns=['Description', '', 'Lines/Ord', 'Units/Line', 'Units/Ord', 'Ea Lines/Ord', 'Eaches/Line', 'Eaches/Ord', 'Cs Lns/Ord', 'Cases/Line', 'Cases/Ord', 'Eaches/Case', 'Pk Lns/Ord'])
            profile_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Statistical values from order profiles - single row with all values
            statistical_values = order_profiles.get('statistical_values', {})
            if statistical_values:
                profile_data = [[
                    'Statistical Values ==>',
                    '',
                    round(statistical_values.get('lines_per_order', 0), 2),
                    round(statistical_values.get('units_per_line', 0), 2),
                    round(statistical_values.get('units_per_order', 0), 2),
                    round(statistical_values.get('each_lines_per_order', 0), 2),
                    round(statistical_values.get('eaches_per_line', 0), 2),
                    round(statistical_values.get('eaches_per_order', 0), 2),
                    round(statistical_values.get('case_lines_per_order', 0), 2),
                    round(statistical_values.get('cases_per_line', 0), 2),
                    round(statistical_values.get('cases_per_order', 0), 2),
                    round(statistical_values.get('eaches_per_case', 0), 2),
                    round(statistical_values.get('pick_lines_per_order', 0), 2)
                ]]
                
                profile_df = pd.DataFrame(profile_data, columns=['Description', '', 'Lines/Ord', 'Units/Line', 'Units/Ord', 'Ea Lines/Ord', 'Eaches/Line', 'Eaches/Ord', 'Cs Lns/Ord', 'Cases/Line', 'Cases/Ord', 'Eaches/Case', 'Pk Lns/Ord'])
                profile_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(profile_data) + 3
        
        # Section 3B: Monthly Volume Analysis - Professional format matching Screenshot 3
        monthly_volumes = order_results.get('monthly_volumes', {})
        if monthly_volumes:
            # Main header with sections - matching Screenshot 3 (12 columns)
            main_header = pd.DataFrame([['Volume by Month - Totals', 'Overall', '', '', '', 'Each Picks', '', '', 'Case Picks', '', '', '']], 
                                     columns=['#', 'Month - Year', 'Orders', 'Lines', 'Overall Volume', 'SKUs', 'Orders', 'Lines', 'Each Only Volume', 'Orders', 'Lines', 'Case Volume'])
            main_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Sub headers (12 columns)
            sub_header = pd.DataFrame([['#', 'Month - Year', 'Orders', 'Lines', 'Overall Volume', 'SKUs', 'Orders', 'Lines', 'Each Only Volume', 'Orders', 'Lines', 'Case Volume']], 
                                    columns=['#', 'Month - Year', 'Orders', 'Lines', 'Overall Volume', 'SKUs', 'Orders', 'Lines', 'Each Only Volume', 'Orders', 'Lines', 'Case Volume'])
            sub_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            monthly_totals = monthly_volumes.get('monthly_totals', {})
            overall_monthly = monthly_totals.get('overall', pd.DataFrame())
            each_monthly = monthly_totals.get('each_picks', pd.DataFrame())
            case_monthly = monthly_totals.get('case_picks', pd.DataFrame())
            
            if not overall_monthly.empty:
                monthly_data = []
                
                for idx, row in overall_monthly.iterrows():
                    month_year = row['Month_Year']
                    
                    # Overall data
                    overall_orders = int(row.get('Orders', 0))
                    overall_lines = int(row.get('Lines', 0))
                    overall_volume = int(row.get('Volume', 0))  # ‚Üê FIXED: Use case equivalent volume
                    overall_skus = int(row.get('SKUs', 0))
                    
                    # Each picks data
                    each_row = each_monthly[each_monthly['Month_Year'] == month_year] if not each_monthly.empty else pd.DataFrame()
                    if len(each_row) > 0:
                        each_orders = int(each_row['Orders'].iloc[0])
                        each_lines = int(each_row['Lines'].iloc[0])
                        each_volume = int(each_row['Volume'].iloc[0])  # ‚Üê FIXED: Use case equivalent volume
                    else:
                        each_orders = each_lines = each_volume = 0
                    
                    # Case picks data
                    case_row = case_monthly[case_monthly['Month_Year'] == month_year] if not case_monthly.empty else pd.DataFrame()
                    if len(case_row) > 0:
                        case_orders = int(case_row['Orders'].iloc[0])
                        case_lines = int(case_row['Lines'].iloc[0])
                        case_volume = int(case_row['Volume'].iloc[0])  # ‚Üê FIXED: Use case equivalent volume
                    else:
                        case_orders = case_lines = case_volume = 0
                    
                    # Add single row for this month (clean format like Screenshot 3) - 12 columns
                    monthly_data.append([
                        idx + 7,  # Start numbering from 7 (as shown in Screenshot 3)
                        month_year,
                        overall_orders, overall_lines, overall_volume, overall_skus,
                        each_orders, each_lines, each_volume,
                        case_orders, case_lines, case_volume
                    ])
                
                monthly_df = pd.DataFrame(monthly_data, columns=['#', 'Month - Year', 'Orders', 'Lines', 'Overall Volume', 'SKUs', 'Orders', 'Lines', 'Each Only Volume', 'Orders', 'Lines', 'Case Volume'])
                monthly_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(monthly_data) + 3
        
        # Section 4: Volume Analysis - Horizontal Layout (2 rows: Cases and Orders)
        volume_analysis = order_results.get('volume_analysis', {})
        if volume_analysis:
            # Main header
            vol_header = pd.DataFrame([['VOLUME ANALYSIS', '', '', '', '', '', '', '']], 
                                    columns=['Type', 'Total Volume', 'Daily Average', 'Daily Median', 'Standard Deviation', 'Minimum Day', 'Maximum Day', 'Coefficient of Variation'])
            vol_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Column headers
            headers = pd.DataFrame([['Type', 'Total Volume', 'Daily Average', 'Daily Median', 'Standard Deviation', 'Minimum Day', 'Maximum Day', 'Coefficient of Variation']], 
                                 columns=['Type', 'Total Volume', 'Daily Average', 'Daily Median', 'Standard Deviation', 'Minimum Day', 'Maximum Day', 'Coefficient of Variation'])
            headers.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            cases_stats = volume_analysis.get('cases', {})
            orders_stats = volume_analysis.get('orders', {})
            
            # Horizontal volume data - Just 2 rows: Cases and Orders
            volume_data = [
                ['Cases', 
                 round(cases_stats.get('total', 0), 2),
                 round(cases_stats.get('mean', 0), 2),
                 round(cases_stats.get('median', 0), 2),
                 round(cases_stats.get('std', 0), 2),
                 round(cases_stats.get('min', 0), 2),
                 round(cases_stats.get('max', 0), 2),
                 f"{round(cases_stats.get('cv', 0) * 100, 1)}%"],
                ['Orders',
                 round(orders_stats.get('total', 0), 2),
                 round(orders_stats.get('mean', 0), 2),
                 round(orders_stats.get('median', 0), 2),
                 round(orders_stats.get('std', 0), 2),
                 round(orders_stats.get('min', 0), 2),
                 round(orders_stats.get('max', 0), 2),
                 '']  # Orders don't have CV typically
            ]
            
            volume_df = pd.DataFrame(volume_data, columns=['Type', 'Total Volume', 'Daily Average', 'Daily Median', 'Standard Deviation', 'Minimum Day', 'Maximum Day', 'Coefficient of Variation'])
            volume_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += len(volume_data) + 3
        
        # Section 5: Percentile Analysis & Capacity Planning - Horizontal Layout
        percentile_analysis = order_results.get('percentile_analysis', {})
        if percentile_analysis:
            # Main header
            perc_header = pd.DataFrame([['PERCENTILE ANALYSIS & CAPACITY PLANNING', '', '', '', '', '', '', '', '']], 
                                     columns=['Percentile', 'Distinct_Customers', 'Distinct_Shipments', 'Distinct_Orders', 'Distinct_SKUs', 'Qty_Ordered_Cases', 'Qty_Ordered_Eaches', 'Total_Case_Equiv', 'Total_Pallet_Equiv'])
            perc_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Column headers
            headers = pd.DataFrame([['Percentile', 'Distinct_Customers', 'Distinct_Shipments', 'Distinct_Orders', 'Distinct_SKUs', 'Qty_Ordered_Cases', 'Qty_Ordered_Eaches', 'Total_Case_Equiv', 'Total_Pallet_Equiv']], 
                                 columns=['Percentile', 'Distinct_Customers', 'Distinct_Shipments', 'Distinct_Orders', 'Distinct_SKUs', 'Qty_Ordered_Cases', 'Qty_Ordered_Eaches', 'Total_Case_Equiv', 'Total_Pallet_Equiv'])
            headers.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            # Get horizontal percentile data
            horizontal_percentiles = percentile_analysis.get('horizontal_percentiles', {})
            
            if horizontal_percentiles:
                percentile_data = []
                
                # Row order matching the target image
                row_order = ['Max', '95.0%ile', '90.0%ile', '85.0%ile', 'Average']
                
                for percentile_name in row_order:
                    if percentile_name in horizontal_percentiles:
                        row_data = horizontal_percentiles[percentile_name]
                        percentile_data.append([
                            percentile_name,
                            round(row_data.get('Distinct_Customers', 0), 1),
                            round(row_data.get('Distinct_Shipments', 0), 1), 
                            round(row_data.get('Distinct_Orders', 0), 1),
                            round(row_data.get('Distinct_SKUs', 0), 1),
                            round(row_data.get('Qty_Ordered_Cases', 0), 1),
                            round(row_data.get('Qty_Ordered_Eaches', 0), 2),
                            round(row_data.get('Total_Case_Equiv', 0), 2),
                            round(row_data.get('Total_Pallet_Equiv', 0), 2)
                        ])
                
                perc_df = pd.DataFrame(percentile_data, columns=['Percentile', 'Distinct_Customers', 'Distinct_Shipments', 'Distinct_Orders', 'Distinct_SKUs', 'Qty_Ordered_Cases', 'Qty_Ordered_Eaches', 'Total_Case_Equiv', 'Total_Pallet_Equiv'])
                perc_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(percentile_data) + 1
            
            # Add capacity planning section (keeping this for completeness)
            capacity_planning = percentile_analysis.get('capacity_planning', {})
            if capacity_planning:
                capacity_header = pd.DataFrame([['CAPACITY RECOMMENDATIONS', '']], columns=['Metric', 'Value'])
                capacity_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += 1
                
                capacity_stats = [
                    ['Normal Capacity (Cases)', round(capacity_planning.get('normal_capacity', 0), 2)],
                    ['Peak Capacity (Cases)', round(capacity_planning.get('peak_capacity', 0), 2)],
                    ['Surge Capacity (Cases)', round(capacity_planning.get('surge_capacity', 0), 2)],
                    ['Normal Utilization %', f"{round(capacity_planning.get('utilization_at_normal', 0), 1)}%"],
                    ['Peak Utilization %', f"{round(capacity_planning.get('utilization_at_peak', 0), 1)}%"]
                ]
                
                capacity_df = pd.DataFrame(capacity_stats, columns=['Metric', 'Value'])
                capacity_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(capacity_stats) + 3
        
        # Section 6: Peak Period Analysis
        peak_analysis = order_results.get('peak_analysis', {})
        if peak_analysis:
            peak_header = pd.DataFrame([['PEAK PERIOD ANALYSIS', '']], columns=['Metric', 'Value'])
            peak_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            peak_stats = []
            peak_periods = peak_analysis.get('peak_periods', {})
            
            if peak_periods:
                for period_type, period_data in peak_periods.items():
                    if isinstance(period_data, dict):
                        peak_stats.append([f"{period_type.replace('_', ' ').title()}", 
                                         f"{period_data.get('period', 'N/A')} ({round(period_data.get('avg_cases', 0), 2)} cases)"])
            
            seasonal_patterns = peak_analysis.get('seasonal_patterns', {})
            if seasonal_patterns:
                peak_stats.append(['', ''])
                peak_stats.append(['SEASONAL PATTERNS', ''])
                for pattern_name, pattern_value in seasonal_patterns.items():
                    peak_stats.append([pattern_name.replace('_', ' ').title(), 
                                     round(pattern_value, 2) if isinstance(pattern_value, (int, float)) else str(pattern_value)])
            
            if peak_stats:
                peak_df = pd.DataFrame(peak_stats, columns=['Metric', 'Value'])
                peak_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
                current_row += len(peak_stats) + 3
        
        # Section 7: Trend Analysis
        trends = order_results.get('trends', {})
        if trends:
            trend_header = pd.DataFrame([['TREND ANALYSIS', '']], columns=['Metric', 'Value'])
            trend_header.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
            current_row += 1
            
            trend_stats = []
            
            # Growth trends
            growth_trends = trends.get('growth_trends', {})
            if growth_trends:
                trend_stats.append(['Cases Growth Trend', f"{round(growth_trends.get('cases_trend', 0), 3)}% per day"])
                trend_stats.append(['Orders Growth Trend', f"{round(growth_trends.get('orders_trend', 0), 3)}% per day"])
                trend_stats.append(['Weekly Growth Rate', f"{round(growth_trends.get('weekly_growth', 0), 2)}%"])
            
            # Trend quality metrics
            trend_quality = trends.get('trend_quality', {})
            if trend_quality:
                trend_stats.append(['', ''])
                trend_stats.append(['TREND RELIABILITY', ''])
                trend_stats.append(['Cases R-squared', round(trend_quality.get('cases_r_squared', 0), 3)])
                trend_stats.append(['Orders R-squared', round(trend_quality.get('orders_r_squared', 0), 3)])
                trend_stats.append(['Trend Confidence', trend_quality.get('trend_strength', 'N/A')])
            
            if trend_stats:
                trend_df = pd.DataFrame(trend_stats, columns=['Metric', 'Value'])
                trend_df.to_excel(writer, sheet_name='Order_Analysis', startrow=current_row, index=False, header=False)
    
    def _create_sku_analysis_sheet(self, writer):
        """Create SKU analysis sheet"""
        if 'sku_analysis' not in self.analysis_results:
            return
        
        if self.verbose:
            print("Creating SKU Analysis sheet...")
        
        sku_results = self.analysis_results['sku_analysis']
        
        # SKU performance details
        sku_performance = sku_results.get('sku_performance', {})
        if 'sku_details' in sku_performance:
            sku_df = sku_performance['sku_details']
            # Limit to top 1000 SKUs to avoid Excel size issues
            sku_df_limited = sku_df.head(1000)
            sku_df_limited.to_excel(writer, sheet_name='SKU_Analysis', index=False)
        
        # Category analysis if available
        category_analysis = sku_results.get('category_analysis', {})
        if 'category_summary' in category_analysis:
            category_df = category_analysis['category_summary']
            category_df.to_excel(writer, sheet_name='SKU_Analysis', startcol=len(sku_df_limited.columns) + 2, index=False)
        
        # Velocity analysis
        velocity_analysis = sku_results.get('velocity_analysis', {})
        if 'velocity_summary' in velocity_analysis:
            velocity_df = velocity_analysis['velocity_summary']
            start_row = len(sku_df_limited) + 3
            velocity_df.to_excel(writer, sheet_name='SKU_Analysis', startrow=start_row, index=False)
    
    def _create_abc_fms_sheet(self, writer):
        """Create ABC-FMS analysis sheet"""
        if 'abc_fms_analysis' not in self.analysis_results:
            return
        
        if self.verbose:
            print("Creating ABC-FMS Analysis sheet...")
        
        abc_results = self.analysis_results['abc_fms_analysis']
        
        # SKU classifications
        sku_classifications = abc_results.get('sku_classifications', {})
        if 'sku_with_classifications' in sku_classifications:
            sku_df = sku_classifications['sku_with_classifications']
            # Limit to top 1000 for Excel performance
            sku_df_limited = sku_df.head(1000)
            sku_df_limited.to_excel(writer, sheet_name='ABC_FMS_Analysis', index=False)
        
        # Cross-tabulation matrix
        cross_tab = abc_results.get('cross_tabulation', {})
        if 'segment_details' in cross_tab:
            segment_df = cross_tab['segment_details']
            segment_df.to_excel(writer, sheet_name='ABC_FMS_Analysis', startcol=len(sku_df_limited.columns) + 2, index=False)
        
        # Strategic recommendations
        strategic_recs = abc_results.get('strategic_recommendations', {})
        if 'recommendations' in strategic_recs:
            recs_data = []
            for rec in strategic_recs['recommendations']:
                recs_data.append([
                    rec.get('segment', ''),
                    rec.get('priority', ''),
                    rec.get('recommendation', ''),
                    ', '.join(rec.get('actions', []))
                ])
            
            if recs_data:
                recs_df = pd.DataFrame(recs_data, columns=['Segment', 'Priority', 'Recommendation', 'Actions'])
                start_row = len(sku_df_limited) + 3
                recs_df.to_excel(writer, sheet_name='ABC_FMS_Analysis', startrow=start_row, index=False)
    
    def _create_inventory_analysis_sheet(self, writer):
        """Create inventory analysis sheet (placeholder for future implementation)"""
        if self.verbose:
            print("Creating Inventory Analysis sheet...")
        
        # Placeholder data - in future this would contain actual inventory analysis
        placeholder_data = [
            ['Inventory Analysis', 'Status'],
            ['Module', 'Available in future version'],
            ['Description', 'Stock levels, reorder points, safety stock analysis'],
            ['Implementation', 'Planned for next release']
        ]
        
        placeholder_df = pd.DataFrame(placeholder_data, columns=['Item', 'Value'])
        placeholder_df.to_excel(writer, sheet_name='Inventory_Analysis', index=False)
    
    def _create_receipt_analysis_sheet(self, writer):
        """Create receipt analysis sheet"""
        if 'receipt_analysis' not in self.analysis_results:
            return
        
        if self.verbose:
            print("Creating Receipt Analysis sheet...")
        
        receipt_results = self.analysis_results['receipt_analysis']
        
        # Daily patterns
        daily_patterns = receipt_results.get('daily_patterns', {})
        if 'daily_data' in daily_patterns:
            daily_df = daily_patterns['daily_data']
            daily_df.to_excel(writer, sheet_name='Receipt_Analysis', index=False)
        
        # Supplier performance
        supplier_performance = receipt_results.get('supplier_performance', {})
        if 'truck_details' in supplier_performance:
            truck_df = supplier_performance['truck_details']
            # Limit to top 100 trucks
            truck_df_limited = truck_df.head(100)
            truck_df_limited.to_excel(writer, sheet_name='Receipt_Analysis', startcol=len(daily_df.columns) + 2, index=False)
        
        # Performance summary
        if 'performance_summary' in supplier_performance:
            perf_df = supplier_performance['performance_summary']
            start_row = len(daily_df) + 3
            perf_df.to_excel(writer, sheet_name='Receipt_Analysis', startrow=start_row, index=False)
    
    def _create_recommendations_sheet(self, writer):
        """Create consolidated recommendations sheet"""
        if self.verbose:
            print("Creating Recommendations sheet...")
        
        all_recommendations = []
        
        # Collect recommendations from all analyses
        analysis_modules = ['order_analysis', 'sku_analysis', 'abc_fms_analysis', 'receipt_analysis']
        
        for module in analysis_modules:
            if module in self.analysis_results:
                module_results = self.analysis_results[module]
                
                # Check for recommendations in different possible locations
                recommendations = None
                if 'recommendations' in module_results:
                    recs_data = module_results['recommendations']
                    if isinstance(recs_data, dict) and 'recommendations' in recs_data:
                        recommendations = recs_data['recommendations']
                    elif isinstance(recs_data, list):
                        recommendations = recs_data
                
                # Also check for strategic recommendations
                if 'strategic_recommendations' in module_results:
                    strategic_recs = module_results['strategic_recommendations']
                    if isinstance(strategic_recs, dict) and 'recommendations' in strategic_recs:
                        strategic_recommendations = strategic_recs['recommendations']
                        if recommendations:
                            recommendations.extend(strategic_recommendations)
                        else:
                            recommendations = strategic_recommendations
                
                if recommendations:
                    for rec in recommendations:
                        all_recommendations.append([
                            module.replace('_', ' ').title(),
                            rec.get('category', rec.get('segment', 'General')),
                            rec.get('priority', 'Medium'),
                            rec.get('recommendation', ''),
                            rec.get('impact', rec.get('actions', ''))
                        ])
        
        if all_recommendations:
            recs_df = pd.DataFrame(all_recommendations, 
                                 columns=['Analysis Module', 'Category', 'Priority', 'Recommendation', 'Expected Impact'])
            
            # Sort by priority
            priority_order = {'Critical': 1, 'High': 2, 'Medium': 3, 'Low': 4}
            recs_df['Priority_Order'] = recs_df['Priority'].map(priority_order).fillna(5)
            recs_df = recs_df.sort_values('Priority_Order').drop('Priority_Order', axis=1)
            
            recs_df.to_excel(writer, sheet_name='Recommendations', index=False)
        else:
            # Create placeholder if no recommendations found
            placeholder_df = pd.DataFrame([['No recommendations available', '', '', '', '']], 
                                        columns=['Analysis Module', 'Category', 'Priority', 'Recommendation', 'Expected Impact'])
            placeholder_df.to_excel(writer, sheet_name='Recommendations', index=False)
    
    def _create_configuration_sheet(self, writer):
        """Create configuration documentation sheet"""
        if self.verbose:
            print("Creating Configuration sheet...")
        
        config_data = []
        
        # Analysis configuration
        config_data.append(['ANALYSIS CONFIGURATION', ''])
        config_data.append(['Configuration Generated', datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
        config_data.append(['', ''])
        
        if self.configuration:
            for category, settings in self.configuration.items():
                config_data.append([f'{category.upper().replace("_", " ")}', ''])
                if isinstance(settings, dict):
                    for key, value in settings.items():
                        config_data.append([key.replace('_', ' ').title(), str(value)])
                else:
                    config_data.append(['Value', str(settings)])
                config_data.append(['', ''])
        
        # Add default settings from config module
        config_data.append(['DEFAULT SETTINGS', ''])
        config_data.append(['ABC A Threshold', f"{config.DEFAULT_ABC_THRESHOLDS['A_THRESHOLD']}%"])
        config_data.append(['ABC B Threshold', f"{config.DEFAULT_ABC_THRESHOLDS['B_THRESHOLD']}%"])
        config_data.append(['FMS Fast Threshold', f"{config.DEFAULT_FMS_THRESHOLDS['F_THRESHOLD']}%"])
        config_data.append(['FMS Medium Threshold', f"{config.DEFAULT_FMS_THRESHOLDS['M_THRESHOLD']}%"])
        config_data.append(['Default Percentiles', ', '.join(map(str, config.DEFAULT_PERCENTILE_LEVELS))])
        
        config_df = pd.DataFrame(config_data, columns=['Setting', 'Value'])
        config_df.to_excel(writer, sheet_name='Configuration', index=False)
    
    def _create_raw_data_summary(self, writer):
        """Create raw data summary sheet"""
        if self.verbose:
            print("Creating Raw Data Summary sheet...")
        
        summary_data = []
        
        # Data source information
        summary_data.append(['RAW DATA SUMMARY', ''])
        summary_data.append(['Report Generated', datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
        summary_data.append(['Tool Version', 'Warehouse Analysis Tool V2'])
        summary_data.append(['', ''])
        
        # Data availability summary
        if 'data_loader' in self.analysis_results:
            data_results = self.analysis_results['data_loader']
            
            summary_data.append(['DATA AVAILABILITY', ''])
            
            for data_type, data_info in data_results.get('data', {}).items():
                if isinstance(data_info, pd.DataFrame):
                    summary_data.append([data_type.replace('_', ' ').title(), f'{len(data_info)} records'])
                else:
                    summary_data.append([data_type.replace('_', ' ').title(), 'Available'])
            
            summary_data.append(['', ''])
            
            # Validation results
            validation_results = data_results.get('validation', {})
            if validation_results:
                summary_data.append(['DATA VALIDATION', ''])
                for data_type, validation in validation_results.items():
                    if isinstance(validation, dict):
                        summary_data.append([f'{data_type.replace("_", " ").title()} - Total Rows', validation.get('total_rows', 'N/A')])
                        summary_data.append([f'{data_type.replace("_", " ").title()} - Date Range (Days)', validation.get('date_range_days', 'N/A')])
        
        # Analysis modules executed
        summary_data.append(['', ''])
        summary_data.append(['ANALYSIS MODULES EXECUTED', ''])
        
        executed_modules = [key for key in self.analysis_results.keys() if key != 'data_loader']
        for module in executed_modules:
            summary_data.append([module.replace('_', ' ').title(), 'Completed'])
        
        summary_df = pd.DataFrame(summary_data, columns=['Item', 'Value'])
        summary_df.to_excel(writer, sheet_name='Raw_Data_Summary', index=False)

# Test function for standalone execution
if __name__ == "__main__":
    print("ExcelGenerator module - ready for use")
    print("This module requires analysis results to function.")
    print("Use within the main analysis pipeline for proper functionality.")